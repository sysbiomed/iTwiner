---
title: "iTwiner regularizer"
author: "Carolina Peixoto"
output: 
  html_document:
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: inline
params:
  seed: !r 2010
  nfolds: !r 10
  nsample: 30
---

```{r}
set.seed(params$seed)
```

# Install packages

## Required libraries
```{r message = FALSE}
library(funModeling) 
library(tidyverse) 
library(Hmisc)
library(biomaRt)
library(survminer)
library(glmnet)
library(glmSparseNet)
library(PRROC)
library(propagate)
library(lsa)
library(edgeR)
library(limma)
library(Glimma)
library(gplots)
library(DESeq2)
library(RColorBrewer)
library(GEOquery)
library(tibble)
library ( DESeq2 )
library(NMF)
library(ISLR)
library(tree)
library(readxl)
# library(ggbiplot)
library(caret)
library(rpart)
library(rpart.plot)
library(futile.logger)
library(ggpubr)
library(rstatix)
library(writexl)
```



# Data 
## RnaSeq 
- RNAseq data from CRC patients provided by Hospital de Santa Maria (Lisbon)

```{r, message = FALSE}
rnaseq1 <- read_excel("data/rnaseq_LCosta.xlsx")
rnaseq1 <- as.data.frame(rnaseq1)

ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
hgnc_swissprot <- getBM(attributes=c('ensembl_gene_id','hgnc_symbol'),filters = 'ensembl_gene_id', values = rnaseq1$...1, mart = ensembl)
hgnc_swissprot[1:3,1:2]

hgnc_swissprot <- hgnc_swissprot[!duplicated(hgnc_swissprot$ensembl_gene_id), ]


rnaseq1 <- rnaseq1[rnaseq1$...1 %in% 
                              hgnc_swissprot$ensembl_gene_id,]

rnaseq1$genes <- hgnc_swissprot$hgnc_symbol
rnaseq1 <- rnaseq1[!duplicated(rnaseq1$genes), ]
which(is.na(rnaseq1[,101]))
# rnaseq <- rnaseq[-38532,]
rownames(rnaseq1) <- rnaseq1$genes
rnaseq1 <- rnaseq1[,-c(1,101)]
rnaseq1 <- t(rnaseq1)
which(colnames(rnaseq1)=="")
rnaseq1 <- rnaseq1[,-1599]
rnaseq1 <- as.data.frame(rnaseq1)
rnaseq1$row <- rownames(rnaseq1)
dim(rnaseq1)


rnaseq2 <- read_excel("data/rnaseq_illumina.xlsx")
rnaseq2 <- as.data.frame(rnaseq2)

ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
hgnc_swissprot <- getBM(attributes=c('ensembl_gene_id','hgnc_symbol'),filters = 'ensembl_gene_id', values = rnaseq2$...1, mart = ensembl)
hgnc_swissprot[1:3,1:2]

hgnc_swissprot <- hgnc_swissprot[!duplicated(hgnc_swissprot$ensembl_gene_id), ]


rnaseq2 <- rnaseq2[rnaseq2$...1 %in% 
                              hgnc_swissprot$ensembl_gene_id,]

rnaseq2$genes <- hgnc_swissprot$hgnc_symbol
rnaseq2 <- rnaseq2[!duplicated(rnaseq2$genes), ]
which(is.na(rnaseq2[,88]))
# rnaseq <- rnaseq[-38532,]
rownames(rnaseq2) <- rnaseq2$genes
rnaseq2 <- rnaseq2[,-c(1,88)]
rnaseq2 <- t(rnaseq2)
which(colnames(rnaseq2)=="")
rnaseq2 <- rnaseq2[,-1599]
rnaseq2 <- as.data.frame(rnaseq2)
rnaseq2$row <- rownames(rnaseq2)
dim(rnaseq2)
```


```{r}
rnaseq <- rbind(rnaseq1,rnaseq2)
rnaseq1 <- rnaseq[!duplicated(rnaseq$row),]
rnaseq1 <- rnaseq1[,-39475]
rnaseq1 <- rnaseq1[ order(row.names(rnaseq1)), ]
```


## Clinic 

- clinical data from CRC patients provided by Hospital de Santa Maria (Lisbon) 

```{r, message = FALSE}
DATASET1 <- read_excel("data/DATASET1NEW_illumina.xlsx")
DATASET1 <- DATASET1[ order(DATASET1$ID), ]
rownames(DATASET1) <- DATASET1$ID

rnaseq1 <- as.data.frame(rnaseq1[rownames(rnaseq1) %in% 
                         rownames(DATASET1),])

DATASET1 <- as.data.frame(DATASET1[rownames(DATASET1) %in% 
                         rownames(rnaseq1),])


clinic1 <- DATASET1[,-c(1,8,9)]
rownames(clinic1) <- DATASET1$ID

```

- Divide data into 3 smaller datasets 

```{r}
set.seed(2010)
# imbalanced data
prop.table(table(DATASET1$class))

df_p <- DATASET1[which(DATASET1$class == "P"),]
df_pm <- DATASET1[which(DATASET1$class == "Pm"),]
### setting negative counts to be same as positive counts - so that the data is balanced
nsample <- params$nsample
pick_negative <- sample(df_p$ID, nsample)
df_p1f <- df_p[df_p$ID %in% pick_negative, ] 
df_p2 <- subset(df_p,!(ID %in% pick_negative))

nsample <- 25
pick_negative <- sample(df_p2$ID, nsample)
df_p2f <- df_p2[df_p2$ID %in% pick_negative, ] 
df_p3f <- subset(df_p2,!(ID %in% pick_negative))


df1 <- rbind(df_p1f,df_pm)
df2 <- rbind(df_p2f,df_pm)
df3 <- rbind(df_p3f,df_pm)

dim(df1)
dim(df2)
dim(df3)
table(df1$class)
table(df2$class)
table(df3$class)


clinic1_bal <- df1[,-c(1,8,9)]
datasurv1 <- as.data.frame(df1[,8:9])
rownames(clinic1_bal) <- df1$ID
rownames(datasurv1) <- df1$ID

clinic2_bal <- df2[,-c(1,8,9)]
datasurv2 <- as.data.frame(df2[,8:9])
rownames(clinic2_bal) <- df2$ID
rownames(datasurv2) <- df2$ID

clinic3_bal <- df3[,-c(1,8,9)]
datasurv3 <- as.data.frame(df3[,8:9])
rownames(clinic3_bal) <- df3$ID
rownames(datasurv3) <- df3$ID
```









# Analysis

- Run following code for each dataset used (df1,df2,df3) 

## DATASET 1 

- Here we give the example for dataset 1
(to test other datasets replace x to the following dfx, datasetx_bal, and clinicx_bal)
ps: don't forget to change save.image("~resultsx_2010.RData") to save the data of each dataset


```{r}
DATASET1_bal <- df1
DATASET1 <- DATASET1_bal
clinic1 <- clinic1_bal
```

- Split dataset in two groups for classification: 
  -- P -> non-metastatic (CLASS = 1)
  -- PM -> metastatic (CLASS = 0)

```{r, warning=FALSE}
primM <- DATASET1 %>%
  filter(str_detect(class, "m"))
rownames(primM) <- primM$ID
primN <- DATASET1 %>%
  filter(!str_detect(class, "Pm"))
rownames(primN) <- primN$ID

clinic_prim <- DATASET1

rnaprimM <- rnaseq1[rownames(rnaseq1) %in% 
                         rownames(primM),]

rnaprimN <- rnaseq1[rownames(rnaseq1) %in% 
                         rownames(primN),]

rnaprim <- rbind(rnaprimM,rnaprimN)
```

- removing variables with sd=0

```{r, warning=FALSE}
xmet <- rnaprimM [,sapply(seq(ncol(rnaprimM)), function(ix) {sd(rnaprimM[,ix])}) != 0] 
xnon <- rnaprimN[,sapply(seq(ncol(rnaprimN)), function(ix) {sd(rnaprimN[,ix])}) != 0] 

xmet_less <- xmet[,which(colnames(xmet) %in% colnames(xnon))]
xnon_less <- xnon[,which(colnames(xnon) %in% colnames(xmet))]

# normalizing data
xmet_norm <- scale(log2(xmet_less+1)) 
xnon_norm <- scale(log2(xnon_less+1)) 

xdataT <- rbind(xmet_less,xnon_less)
xdataT <- xdataT[ order(row.names(xdataT)), ]


rm(xmet,xmet_less,xnon,xnon_less,rnaprimM,rnaprimN)
```

- weight vector that penalizes genes with greater distances between Pm and P correlation matrices - TWINER

```{r, warning=FALSE}
#xmet_cor <- Matrix(cor(xmet_norm), sparse = TRUE)
xmet_cor <- cor(xmet_norm)
#xmet_cor <- as.data.frame(xmet_cor)
xnon_cor <- cor(xnon_norm)
#xnon_cor <- as.data.frame(xnon_cor)
```

```{r}
# angular distance
ang_weight <- vector()
for (i in 1:dim(xmet_cor)[2]){ 
ang_weight[i] <- acos(cosine(xmet_cor[,i],xnon_cor[,i]))/pi
}

## normalized weights

weights <- ang_weight / max(ang_weight)
hist(weights,main="w")


pen_weight1 <- 1 / weights
hist(pen_weight1, main="1 / w")

rm(xmet_cor,xnon_cor)
```

### Exploratory analysis

- All dataset x

```{r}
clinical <- as.data.frame(clinic1_bal)


basic_eda <- function(clinical)
{
  glimpse(clinical)
  #df_Status(clinical)
  freq(clinical) 
  profiling_num(clinical)
  plot_num(clinical)
  describe(clinic1)
}
basic_eda(clinical)

a <- na.omit(clinical$Age)
mean(a)
``` 

- Only patients that do not metastasize

```{r}
clinical_p <- clinic1_bal %>%
  filter(!str_detect(class, "Pm"))


basic_eda <- function(clinical_p)
{
  glimpse(clinical_p)
  #df_Status(clinical_p)
  freq(clinical_p) 
  profiling_num(clinical_p)
  plot_num(clinical_p)
  describe(clinical_p)
}
basic_eda(clinical_p)

a <- na.omit(clinical_p$Age)
mean(a)
```

- Only patients that do metastasize

```{r}
clinical_Pm <- clinic1_bal%>%
  filter(str_detect(class, "Pm"))


basic_eda <- function(clinical_Pm)
{
  glimpse(clinical_Pm)
  #df_Status(clinical_Pm)
  freq(clinical_Pm) 
  profiling_num(clinical_Pm)
  plot_num(clinical_Pm)
  describe(clinical_Pm)
}
basic_eda(clinical_Pm)

a <- na.omit(clinical_Pm$Age)
mean(a)

```

- Statistic differences between patients groups regarding several variables

```{r}
clinical_factor <- clinic1_bal
clinical_factor <- clinical_factor %>%
  mutate_if(sapply(clinical_factor, is.character), as.factor)
#clinical_factor <- na.omit(clinical_factor)

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  organ), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Sex), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

clinical_factor1 <- clinical_factor %>%
  filter(!str_detect(sidedness, "rectum"))

ggplot(data = clinical_factor1) + 
  geom_bar(mapping = aes(x = class, fill =  sidedness), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Stage), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4", "#000080"))


clinical_factor %>%
  ggplot( aes(x=Age, fill=class)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) 
    labs(fill="")

```

```{r}
stat_data_organ <- table(clinical_factor$class,clinical_factor$organ)
#fazer plot(...)
fisher.test(stat_data_organ)

stat_data_sex <- table(clinical_factor$class,clinical_factor$Sex)
fisher.test(stat_data_sex)

stat_data_stage <- table(clinical_factor$class,clinical_factor$Stage)
fisher.test(stat_data_stage)

stat_data_side <- table(clinical_factor$class,clinical_factor$sidedness)
fisher.test(stat_data_side)



hist(clinical_factor$Age[clinical_factor$class=="P"])
hist(clinical_factor$Age[clinical_factor$class=="Pm"])

tapply(clinical_factor$Age,clinical_factor$class, summary)
t.test(Age ~ class, clinical_factor)
```


### Survival analysis

#### Stage

```{r}
data <- merge(datasurv1, clinical, by="row.names")

fit <- survfit(Surv(time, Status) ~ Stage, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ Stage, data = data)
surv.stage

```


#### Class - PM vs. P

```{r}

fit <- survfit(Surv(time, Status) ~ class, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ class, data = data)
surv.stage

```


#### Sidedness

```{r}
newdata <- data[-which(data$sidedness == "rectum"),]
fit <- survfit(Surv(time, Status) ~ sidedness, data = newdata)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = newdata, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ sidedness, data = newdata)
surv.stage

```


### DEGs

```{r, warning=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                         rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_d1.xlsx")

top100_deg <- rownames(genes_deg[1:100,])
# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)
top100_high <- rownames(high[1:100,])

#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)
top100_low <- rownames(low[1:100,])
```

### Classification

- In this work we tested 3 different types of classification: 1) Classification without regularization based on DEGs; 2) Classification with regularization (EN and iTwiner); 3) Classification without regularization based on genes selected by regularized logistic regression;

```{r}
xdata.raw <- xdataT

# keep features with standard deviation > 0
xdata <- xdata.raw[,sapply(seq(ncol(xdata.raw)), function(ix) {sd(xdata.raw[,ix])}) != 0]

ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

# ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```

#### 1) Classification without regularization based on DEGs

Five classifiers were used: Decision trees, linear and radial support vector machines, logistic regression and random forest

- Lets pick up the 50 deferentially expressed genes with lowest pvalue found above

```{r}
xdata <- xdataT[,top100_deg[1:50]]

nomesgenes <- colnames(xdata)
colnames(xdata) <- paste0("Var", 1:50)
colnames(ydata) <- c("class","row")
xdata$type <- as.factor(ydata$class)

#xdata <- xdata[colMeans(xdata == 0) <= 0.6] #delete genes that have null values in at least 60% of the samples

```

- Test the different classifiers 100 times to obtain median values for the measures of model performance such as accuracy, misclassification, sensitivity and specificity, among others

```{r, echo=FALSE}

times_boot <- 100

acc <- matrix(0,5,times_boot)
kappa<- matrix(0,5,times_boot)
sensitivity<- matrix(0,5,times_boot)
specificity <- matrix(0,5,times_boot)
miscl <- matrix(0,5,times_boot)
fpos <- matrix(0,5,times_boot)
fneg <- matrix(0,5,times_boot)

ids_fn_tree1 <- vector("list")
ids_fn_svmL1 <- vector("list")
ids_fn_svmR1 <- vector("list")
ids_fn_logist1 <- vector("list")
ids_fn_rf1 <- vector("list")

ids_fp_tree1 <- vector("list")
ids_fp_svmL1 <- vector("list")
ids_fp_svmR1 <- vector("list")
ids_fp_logist1 <- vector("list")
ids_fp_rf1 <- vector("list")


run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)


  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  training <- xdata[ixs$train,]
  testing <- xdata[ixs$test,]


# Classification 

## Decision tree
### Fit the model on the training set

control <- rpart.control(minsplit = 4)

model2 <- rpart(type~., data = training, method = 'class', control = control)

# Make predictions on the test data
pred <- model2 %>% predict(testing, type = "class")



  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[1,i] <- length(listafp)
  fneg[1,i] <- length(listafn)
  ids_fn_tree1[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1[[i]] <- rownames(testing[listafp,])


  # tree <- rpart(type~., data=training, method = "class")
  #
  # #Testing the model
  # pred <- predict(object=tree,testing,type="class")

  #Calculating accuracy
  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc[1,i] <- result[["overall"]][["Accuracy"]]
  kappa[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[1,i] <- result[["byClass"]][["Specificity"]]
  miscl[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_Linear, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[2,i] <- length(listafp)
  fneg[2,i] <- length(listafn)
  ids_fn_svmL1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc[2,i] <- result[["overall"]][["Accuracy"]]
  kappa[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[2,i] <- result[["byClass"]][["Specificity"]]
  miscl[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_radial, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    }  else {
      listafn <- c(listafn, a)
    }
  }

  fpos[3,i] <- length(listafp)
  fneg[3,i] <- length(listafn)
  ids_fn_svmR1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc[3,i] <- result[["overall"]][["Accuracy"]]
  kappa[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[3,i] <- result[["byClass"]][["Specificity"]]
  miscl[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


logist <- train(type ~., data = training, method = "LogitBoost",
                trControl=trainControl("cv", number = 10),
                tuneLength = 10)

pred <- predict(logist,newdata = testing)
table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[4,i] <- length(listafp)
  fneg[4,i] <- length(listafn)
  ids_fn_logist1[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc[4,i] <- result[["overall"]][["Accuracy"]]
  kappa[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[4,i] <- result[["byClass"]][["Specificity"]]
  miscl[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)

  pred <- predict(model.rf,newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[5,i] <- length(listafp)
  fneg[5,i] <- length(listafn)
  ids_fn_rf1[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)


  acc[5,i] <- result[["overall"]][["Accuracy"]]
  kappa[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[5,i] <- result[["byClass"]][["Specificity"]]
  miscl[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing)
}

```

##### Measures of model performance

- Accuracy 

```{r}
# acc
acc_trees <- acc[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)

acc_svm <- acc[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)

acc_svmR <- acc[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)

acc_logs <- acc[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)

acc_rf <- acc[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)

miscl_svm <- miscl[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)

miscl_svmR <- miscl[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)

miscl_logs <- miscl[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)

miscl_rf <- miscl[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity[1,]
sensitivity_trees <- na.omit(sensitivity_trees)
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)

sensitivity_svm <- sensitivity[2,]
sensitivity_svm <- na.omit(sensitivity_svm)
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)

sensitivity_svmR <- sensitivity[3,]
sensitivity_svmR <- na.omit(sensitivity_svmR)
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)

sensitivity_logs <- sensitivity[4,]

sensitivity_logs <- na.omit(sensitivity_logs)
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)

sensitivity_rf <- sensitivity[5,]
sensitivity_rf <- na.omit(sensitivity_rf)
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)


```

- Specificity

```{r}
# specificity
specificity_trees <- specificity[1,]
specificity_trees <- na.omit(specificity_trees)
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)

specificity_svm <- specificity[2,]
specificity_svm <- na.omit(specificity_svm)
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)

specificity_svmR <- specificity[3,]
specificity_svmR <- na.omit(specificity_svmR)
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)

specificity_logs <- specificity[4,]
specificity_logs <- na.omit(specificity_logs)
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)

specificity_rf <- specificity[5,]
specificity_rf <- na.omit(specificity_rf)
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)

fneg_svmL <- fneg[2,]
#hist(fneg_svmL)
mean(fneg_svmL)
median(fneg_svmL)

fneg_svmR <- fneg[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)

fneg_logs <- fneg[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)

fneg_rf <- fneg[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
```


#### 2) Classification with regularization (EN and iTwiner)

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID
# 
# # ydata.raw$class <- c(rep(0,28),rep(1,34))
#  
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw)
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```

```{r, echo = FALSE}
times_boot <- 1000

nvar_selected_1 <- matrix(0,2,times_boot)

var_selected_en1 <- vector("list")
var_selected_iTwiner1 <- vector("list")

acc_cox_tr <- matrix(0,2,times_boot)
acc_cox_tes <- matrix(0,2,times_boot)
kappa_cox_tr <- matrix(0,2,times_boot)
kappa_cox_tes <- matrix(0,2,times_boot)
sensitivity_cox_tr <- matrix(0,2,times_boot)
sensitivity_cox_tes <- matrix(0,2,times_boot)
specificity_cox_tr <- matrix(0,2,times_boot)
specificity_cox_tes <- matrix(0,2,times_boot)
miscl_cox_tr <- matrix(0,2,times_boot)
miscl_cox_tes <- matrix(0,2,times_boot)


fpos_reg <- matrix(0,2,times_boot)
fneg_reg <- matrix(0,2,times_boot)

ids_fn_en <- vector("list")
ids_fn_iTwiner <- vector("list")


ids_fp_en <- vector("list")
ids_fp_iTwiner <- vector("list")

run = 1000

i=1
l1=0
while(l1 < 100){
  
  print(l1)
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
# Classification by sparse logistic regression
  
## with the elastic net (EN) penalty
  
  fit_EN1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.2,
                       #foldid=my_foldid,
                       type.measure="mse")
  
  var_selected <- which(fit_EN1$glmnet.fit$beta[,which(fit_EN1$cvm == min(fit_EN1$cvm))] != 0)
  
  nvar_selected_1[1,i] <- length(var_selected)
  
  
  var_selected_en1[[i]] <- names(var_selected)
  
  
  
  if (length(var_selected) > 1){
    
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train$"1"
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("en train ups")} else{
        
        t <- table(ytrain,resp_train)
        result <- confusionMatrix(t)
        
        acc_cox_tr[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[1,i] <- t[1,2]+t[2,1]
        
        rm(var_selected,resp_train,t,result)
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred$"1"
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("en pred ups")} else{
        
        t <- table(ytest,pred)
        result <- confusionMatrix(t)
        
        acc_cox_tes[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[1,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }
    
    fpos_reg[1,i] <- length(listafp)
    fneg_reg[1,i] <- length(listafn)
    ids_fn_en[[i]] <- rownames(xtest[listafn,])
    ids_fp_en[[i]] <- rownames(xtest[listafp,])
    
    
    print("EN")} else{
      print("EN não selecionou variaveis")
    }
  
  rm(pred,t,result)
  
  
  i=i+1
  
  
  rm(xtrain,xtest,ytrain,ytest,ytest)
  
  l1 <- length(which(acc_cox_tr[1,]!=0))
  
}


```

```{r}

i=1
l2=0
while(l2 < 100){
  
  print(i)
  print(l2)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  

## with network information - iTwiner
  
  fit_tco1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.05 ,
                        #foldid=my_foldid,
                        penalty.factor = pen_weight1,
                        type.measure="mse")
  
  var_selected <- which(fit_tco1$glmnet.fit$beta[,which(fit_tco1$cvm == min(fit_tco1$cvm))] != 0)
  
  nvar_selected_1[2,i] <- length(var_selected)
  
  
  var_selected_iTwiner1[[i]] <- names(var_selected)
  
  if (length(var_selected) > 1){
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train$"1"
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("iTwiner train ups")} else{
        
        t <- table(ytrain,resp_train)
        result <- confusionMatrix(t)
        
        acc_cox_tr[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[2,i] <- t[1,2]+t[2,1]
        
        rm(var_selected,resp_train,t,result)
        
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred$"1"
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("iTwiner test ups")} else{
        
        t <- table(ytest,pred)
        result <- confusionMatrix(t)
        
        acc_cox_tes[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[2,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }
    
    fpos_reg[2,i] <- length(listafp)
    fneg_reg[2,i] <- length(listafn)
    ids_fn_iTwiner[[i]] <- rownames(xtest[listafn,])
    ids_fp_iTwiner[[i]] <- rownames(xtest[listafp,])
    
    
    
    print("iTwiner")
    
  } else{
    print("iTwiner não correu")
  }
  
    rm(xtrain,xtest,ytrain,ytest,ytest)
    l2 <- length(which(acc_cox_tr[2,]!=0))
    i=i+1
    }
  
```

##### Measures of model performance

```{r}
runs_en <- which(acc_cox_tr[1,]!=0)
runs_itw <- which(acc_cox_tr[2,]!=0)
```

- Accuracy

```{r}
# EN train
acc_cox_tr_EN <- acc_cox_tr[1,]
acc_cox_tr_EN <- acc_cox_tr_EN[runs_en]
#hist(acc_cox_tr_EN)
mean(acc_cox_tr_EN)  
median(acc_cox_tr_EN)

# EN test
acc_cox_tes_EN <- acc_cox_tes[1,]
acc_cox_tes_EN <- acc_cox_tes_EN[runs_en]
#hist(acc_cox_tes_EN)
mean(acc_cox_tes_EN)
median(acc_cox_tes_EN)

#iTwiner train
acc_cox_tr_iTwiner <- acc_cox_tr[2,]
acc_cox_tr_iTwiner <- acc_cox_tr_iTwiner[runs_itw]
#hist(acc_cox_tr_iTwiner)
mean(acc_cox_tr_iTwiner)
median(acc_cox_tr_iTwiner)

#iTwiner test
acc_cox_tes_iTwiner <- acc_cox_tes[2,]
acc_cox_tes_iTwiner <- acc_cox_tes_iTwiner[runs_itw]
#hist(acc_cox_tes_iTwiner)
mean(acc_cox_tes_iTwiner)
median(acc_cox_tes_iTwiner)
```

- miscl

```{r}
#EN train
miscl_cox_tr_EN <- miscl_cox_tr[1,]
miscl_cox_tr_EN <- miscl_cox_tr_EN[runs_en]
#hist(miscl_cox_tr_EN)
mean(miscl_cox_tr_EN)
median(miscl_cox_tr_EN)
#EN test
miscl_cox_tes_EN <- miscl_cox_tes[1,]
miscl_cox_tes_EN <- miscl_cox_tes_EN[runs_en]
#hist(miscl_cox_tes_EN)
mean(miscl_cox_tes_EN)
median(miscl_cox_tes_EN)

#iTwiner train
miscl_cox_tr_iTwiner <- miscl_cox_tr[2,]
miscl_cox_tr_iTwiner <- miscl_cox_tr_iTwiner[runs_itw]
#hist(miscl_cox_tr_iTwiner)
mean(miscl_cox_tr_iTwiner)
median(miscl_cox_tr_iTwiner)
#iTwiner test
miscl_cox_tes_iTwiner <- miscl_cox_tes[2,]
miscl_cox_tes_iTwiner <- miscl_cox_tes_iTwiner[runs_itw]
#hist(miscl_cox_tes_iTwiner)
mean(miscl_cox_tes_iTwiner)
median(miscl_cox_tes_iTwiner)
```

- sensitivity

```{r}
#EN train
sensitivity_cox_tr_EN <- sensitivity_cox_tr[1,]
sensitivity_cox_tr_EN <- sensitivity_cox_tr_EN[runs_en]
#hist(sensitivity_cox_tr_EN)
mean(sensitivity_cox_tr_EN)
median(sensitivity_cox_tr_EN)
#EN test
sensitivity_cox_tes_EN <- sensitivity_cox_tes[1,]
sensitivity_cox_tes_EN <- sensitivity_cox_tes_EN[runs_en]
#hist(sensitivity_cox_tes_EN)
mean(sensitivity_cox_tes_EN)
median(sensitivity_cox_tes_EN)

#iTwiner train
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr[2,]
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr_iTwiner[runs_itw]
#hist(sensitivity_cox_tr_iTwiner)
mean(sensitivity_cox_tr_iTwiner)
median(sensitivity_cox_tr_iTwiner)
#iTwiner test
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes[2,]
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes_iTwiner[runs_itw]
#hist(sensitivity_cox_tes_iTwiner)
mean(sensitivity_cox_tes_iTwiner)
median(sensitivity_cox_tes_iTwiner)

```

- specificity

```{r}
#EN train
specificity_cox_tr_EN <- specificity_cox_tr[1,]
specificity_cox_tr_EN <- specificity_cox_tr_EN[runs_en]
#hist(specificity_cox_tr_EN)
mean(specificity_cox_tr_EN)
median(specificity_cox_tr_EN)
#EN test
specificity_cox_tes_EN <- specificity_cox_tes[1,]
specificity_cox_tes_EN <- specificity_cox_tes_EN[runs_en]
#hist(specificity_cox_tes_EN)
mean(specificity_cox_tes_EN)
median(specificity_cox_tes_EN)

#iTwiner train
specificity_cox_tr_iTwiner <- specificity_cox_tr[2,]
specificity_cox_tr_iTwiner <- specificity_cox_tr_iTwiner[runs_itw]
#hist(specificity_cox_tr_iTwiner)
mean(specificity_cox_tr_iTwiner)
median(specificity_cox_tr_iTwiner)
#iTwiner test
specificity_cox_tes_iTwiner <- specificity_cox_tes[2,]
specificity_cox_tes_iTwiner <- specificity_cox_tes_iTwiner[runs_itw]
#hist(specificity_cox_tes_iTwiner)
mean(specificity_cox_tes_iTwiner)
median(specificity_cox_tes_iTwiner)
```

- False Neg

```{r}
#EN
fneg_reg_en <- fneg_reg[1,nvar_en]
#hist(fneg_reg_en)
mean(fneg_reg_en)
median(fneg_reg_en)

#iTwiner
fneg_reg_iTwiner <- fneg_reg[2,nvar_tw]
#hist(fneg_reg_iTwiner)
mean(fneg_reg_iTwiner)
median(fneg_reg_iTwiner)
```

- number variables selected

```{r}
# median number of variables selected
nvar_en <- nvar_selected_1[1,]
nvar_en <- nvar_en[runs_en]
mean(nvar_en)
median(nvar_en)

nvar_tw <- nvar_selected_1[2,]
nvar_tw <- nvar_tw[runs_itw]
mean(nvar_tw)
median(nvar_tw)
```

- Names of genes selected

Variables always selected
```{r}
var_selected_alw_select_en <- var_selected_en1[runs_en]
var_selected_alw_select_en1 <-  Reduce(intersect,var_selected_alw_select_en)
print(paste("variables always selected by EN = ",length(var_selected_alw_select_en1)))

var_selected_alw_select_iTwiner <- var_selected_iTwiner1[runs_itw]
var_selected_alw_select_iTwiner1 <-  Reduce(intersect,var_selected_alw_select_iTwiner)
print(paste("variables always selected by iTwiner = ",length(var_selected_alw_select_iTwiner1)))
```

Variables selected in 50 bootstrap samples
```{r}
l = length(var_selected_alw_select_en)
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <-  subset(var_selected_50_select_en, Freq > 0.50*l)
print(paste("variables selected 50% by EN = ",length(var_selected_50_select_en$Var1)))
var_selected_50_select_en$Var1
# 
l = length(var_selected_alw_select_iTwiner)
var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <-  subset(var_selected_50_select_iTwiner, Freq > 0.50*l)
print(paste("variables selected 50% by iTwiner = ",length(var_selected_50_select_iTwiner$Var1)))
var_selected_50_select_iTwiner$Var1
```

- Select the 50 most frequent variables 
```{r}
a <- top100_en[1:50,]
b <- top100_itw[1:50,]
```

```{r}
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <- var_selected_50_select_en[order(var_selected_50_select_en$Freq, decreasing = T),]
hist(var_selected_50_select_en$Freq)
top100_en <- var_selected_50_select_en[1:100,]
top100_en <- top100_en$Var1
top50_en <- top100_en[1:50]


var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <- var_selected_50_select_iTwiner[order(var_selected_50_select_iTwiner$Freq, decreasing = T),]
hist(var_selected_50_select_iTwiner$Freq)
top100_itw <- var_selected_50_select_iTwiner[1:100,]
top100_itw <- top100_itw$Var1
top50_itw <- top100_itw[1:50]
```

variables in common between EN and iTwiner

```{r}
common_var_selected_50_en_iTwiner <- var_selected_50_select_iTwiner$Var1[which(var_selected_50_select_iTwiner$Var1 %in% var_selected_50_select_en$Var1)]
length(common_var_selected_50_en_iTwiner)
common_var_selected_50_en_iTwiner
```

- Variables selected by EN and iTwiner that are DEGs

```{r, warning=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]

nomesgenes <- c(as.vector(top50_en),as.vector(top50_itw))
xdata <- xdata[,nomesgenes]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                 rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                               rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_enitw_d1.xlsx")

# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)


#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)

```

#### 3) Classification based on genes selected by regularized logistic regression

##### EN + Classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_en)
xdata_en <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_en)
colnames(xdata_en) <- paste0("Var", 1:50)
xdata_en$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r, echo=FALSE}
times_boot <- 100

acc_enplus <- matrix(0,5,times_boot)
kappa_enplus<- matrix(0,5,times_boot)
sensitivity_enplus<- matrix(0,5,times_boot)
specificity_enplus <- matrix(0,5,times_boot)
miscl_enplus <- matrix(0,5,times_boot)
fpos_enplus <- matrix(0,5,times_boot)
fneg_enplus <- matrix(0,5,times_boot)

ids_fn_tree1_enplus <- vector("list")
ids_fn_svmL1_enplus <- vector("list")
ids_fn_svmR1_enplus <- vector("list")
ids_fn_logist1_enplus <- vector("list")
ids_fn_rf1_enplus <- vector("list")

ids_fp_tree1_enplus <- vector("list")
ids_fp_svmL1_enplus <- vector("list")
ids_fp_svmR1_enplus <- vector("list")
ids_fp_logist1_enplus <- vector("list")
ids_fp_rf1_enplus <- vector("list")



run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)

  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)

  training <- xdata_en[ixs$train,]
  testing <- xdata_en[ixs$test,]  




# Classification - fazer todos com cross validation

## Decision tree
# Fit the model on the training set



  control <- rpart.control(minsplit = 4)

  model2 <- rpart(type~., data = training, method = 'class', control = control)

  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_enplus[1,i] <- length(listafp)
  fneg_enplus[1,i] <- length(listafn)
  ids_fn_tree1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_enplus[[i]] <- rownames(testing[listafp,])


  # tree <- rpart(type~., data=training, method = "class")
  #
  # #Testing the model
  # pred <- predict(object=tree,testing,type="class")

  #Calculating accuracy
  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_enplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_Linear, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_enplus[2,i] <- length(listafp)
  fneg_enplus[2,i] <- length(listafn)
  ids_fn_svmL1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_enplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_enplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_radial, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_enplus[3,i] <- length(listafp)
  fneg_enplus[3,i] <- length(listafn)
  ids_fn_svmR1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_enplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_enplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)

  pred <- predict(logist,newdata = testing )
  #table(testing$type, pred)



  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_enplus[4,i] <- length(listafp)
  fneg_enplus[4,i] <- length(listafn)
  ids_fn_logist1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_enplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_enplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)

  pred <- predict(model.rf,newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_enplus[5,i] <- length(listafp)
  fneg_enplus[5,i] <- length(listafn)
  ids_fn_rf1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_enplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)


  acc_enplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing)
}

```

###### Measures of model performance

- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)

acc_svm <- acc_enplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)

acc_svmR <- acc_enplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)

acc_logs <- acc_enplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)

acc_rf <- acc_enplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)

miscl_svm <- miscl_enplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)

miscl_svmR <- miscl_enplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)

miscl_logs <- miscl_enplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)

miscl_rf <- miscl_enplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus[1,]
sensitivity_trees <- na.omit(sensitivity_trees)
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus[3,]
sensitivity_svmR <- na.omit(sensitivity_svmR)
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)


```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus[1,]
specificity_trees <- na.omit(specificity_trees)
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)

specificity_svm <- specificity_enplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)

specificity_svmR <- specificity_enplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)

specificity_logs <- specificity_enplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)

specificity_rf <- specificity_enplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)

```

- False Neg

```{r}

# fneg
fneg_trees <- fneg_enplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)

fneg_svmL <- fneg_enplus[2,]
#hist(fneg_svmL)
mean(fneg_svmL)
median(fneg_svmL)

fneg_svmR <- fneg_enplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)

fneg_logs <- fneg_enplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)

fneg_rf <- fneg_enplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
```


##### iTwiner + classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_itw)
xdata_iTwiner <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_iTwiner)
colnames(xdata_iTwiner) <- paste0("Var", 1:50)
xdata_iTwiner$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r, echo=FALSE}
# Performing 100 train and test
times_boot <- 100

acc_tcoxplus <- matrix(0,5,times_boot)
kappa_tcoxplus<- matrix(0,5,times_boot)
sensitivity_tcoxplus<- matrix(0,5,times_boot)
specificity_tcoxplus <- matrix(0,5,times_boot)
miscl_tcoxplus <- matrix(0,5,times_boot)
fpos_tcoxplus <- matrix(0,5,times_boot)
fneg_tcoxplus <- matrix(0,5,times_boot)

ids_fn_tree1_tcoxplus <- vector("list")
ids_fn_svmL1_tcoxplus <- vector("list")
ids_fn_svmR1_tcoxplus <- vector("list")
ids_fn_logist1_tcoxplus <- vector("list")
ids_fn_rf1_tcoxplus <- vector("list")

ids_fp_tree1_tcoxplus <- vector("list")
ids_fp_svmL1_tcoxplus <- vector("list")
ids_fp_svmR1_tcoxplus <- vector("list")
ids_fp_logist1_tcoxplus <- vector("list")
ids_fp_rf1_tcoxplus <- vector("list")


run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)

  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)

  training <- xdata_iTwiner[ixs$train,]
  testing <- xdata_iTwiner[ixs$test,]  


# Classification - fazer todos com cross validation

## Decision tree
# Fit the model on the training set
control <- rpart.control(minsplit = 4)

  model2 <- rpart(type~., data = training, method = 'class', control = control)

  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_tcoxplus[1,i] <- length(listafp)
  fneg_tcoxplus[1,i] <- length(listafn)
  ids_fn_tree1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_tcoxplus[[i]] <- rownames(testing[listafp,])


  # tree <- rpart(type~., data=training, method = "class")
  #
  # #Testing the model
  # pred <- predict(object=tree,testing,type="class")

  #Calculating accuracy
  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_tcoxplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_Linear, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_tcoxplus[2,i] <- length(listafp)
  fneg_tcoxplus[2,i] <- length(listafn)
  ids_fn_svmL1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_tcoxplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_tcoxplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  pred <- predict(svm_radial, newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    }  else {
      listafn <- c(listafn, a)
    }
  }

  fpos_tcoxplus[3,i] <- length(listafp)
  fneg_tcoxplus[3,i] <- length(listafn)
  ids_fn_svmR1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_tcoxplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_tcoxplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)

  pred <- predict(logist,newdata = testing )
  #table(testing$type, pred)



  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_tcoxplus[4,i] <- length(listafp)
  fneg_tcoxplus[4,i] <- length(listafn)
  ids_fn_logist1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_tcoxplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)

  acc_tcoxplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)

  pred <- predict(model.rf,newdata = testing)
  #table(testing$type, pred)


  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos_tcoxplus[5,i] <- length(listafp)
  fneg_tcoxplus[5,i] <- length(listafn)
  ids_fn_rf1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_tcoxplus[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(testing$type,pred)
  result <- confusionMatrix(t)


  acc_tcoxplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing)
}

```


###### Measures of model performance
 
- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)

acc_svm <- acc_tcoxplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)

acc_svmR <- acc_tcoxplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)

acc_logs <- acc_tcoxplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)

acc_rf <- acc_tcoxplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_tcoxplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)

miscl_svm <- miscl_tcoxplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)

miscl_svmR <- miscl_tcoxplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)

miscl_logs <- miscl_tcoxplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)

miscl_rf <- miscl_tcoxplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus[1,]
sensitivity_trees <- na.omit(sensitivity_trees)
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus[3,]
sensitivity_svmR <- na.omit(sensitivity_svmR)
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)


```

- Specificity

```{r}

# specificity
specificity_trees <- specificity_tcoxplus[1,]
specificity_trees <- na.omit(specificity_trees)
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)

specificity_svm <- specificity_tcoxplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)

specificity_svmR <- specificity_tcoxplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)

specificity_logs <- specificity_tcoxplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)

specificity_rf <- specificity_tcoxplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)

```

- False Neg

```{r}

# fneg
fneg_trees <- fneg_tcoxplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)

fneg_svmL <- fneg_tcoxplus[2,]
#hist(fneg_svmL)
mean(fneg_svmL)
median(fneg_svmL)

fneg_svmR <- fneg_tcoxplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)

fneg_logs <- fneg_tcoxplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)

fneg_rf <- fneg_tcoxplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
```

```{r}
# save results

save.image("~/results1_2010.RData")
```

### Data final 

```{r}
dt1 <- acc[1,]
dt_en1 <- acc_enplus[1,]
dt_iTwiner1 <- acc_tcoxplus[1,]
#dt_hub <- acc_hubplus[1,]

acc_dt1 <- as.data.frame(c(dt1,dt_en1, dt_iTwiner1
                           #,dt_hub
))
colnames(acc_dt1) <- "acc"
#acc_dt$group <- "HUB + DT"
#acc_dt$group[1:100] <- "DT"
acc_dt1$group <- "DT"
acc_dt1$group[101:200] <- "EN + DT"
acc_dt1$group[201:300] <- "iTwiner + DT"
acc_dt1<- acc_dt1 %>% mutate_if(is.character,factor)
# acc_dt$group <- ordered(acc_dt$group, levels = c("DT", "EN + DT","iTwiner + DT", "HUB + DT"))
acc_dt1$group <- ordered(acc_dt1$group, levels = c("DT", "EN + DT","iTwiner + DT"))

acc_dt1$dataset <- "DATASET1"



svmL1 <- acc[2,]
svmL_en1 <- acc_enplus[2,]
svmL_iTwiner1 <- acc_tcoxplus[2,]

acc_svmL1 <- as.data.frame(c(svmL1,svmL_en1, svmL_iTwiner1
                             #,svmL_hub
))
colnames(acc_svmL1) <- "acc"
acc_svmL1$group <- "svmL"
acc_svmL1$group[101:200] <- "EN + svmL"
acc_svmL1$group[201:300] <- "iTwiner + svmL"
acc_svmL1<- acc_svmL1 %>% mutate_if(is.character,factor)
acc_svmL1$group <- ordered(acc_svmL1$group, levels = c("svmL", "EN + svmL","iTwiner + svmL"))

acc_svmL1$dataset <- "DATASET1"




svmR1 <- acc[3,]
svmR_en1 <- acc_enplus[3,]
svmR_iTwiner1 <- acc_tcoxplus[3,]

acc_svmR1 <- as.data.frame(c(svmR1,svmR_en1, svmR_iTwiner1
                             #,svmR_hub
))
colnames(acc_svmR1) <- "acc"
acc_svmR1$group <- "svmR"
acc_svmR1$group[101:200] <- "EN + svmR"
acc_svmR1$group[201:300] <- "iTwiner + svmR"
acc_svmR1<- acc_svmR1 %>% mutate_if(is.character,factor)
acc_svmR1$group <- ordered(acc_svmR1$group, levels = c("svmR", "EN + svmR","iTwiner + svmR"))

acc_svmR1$dataset <- "DATASET1"






logist1 <- acc[4,]
logist_en1 <- acc_enplus[4,]
logist_iTwiner1 <- acc_tcoxplus[4,]

acc_logist1 <- as.data.frame(c(logist1,logist_en1, logist_iTwiner1
                             #,logist_hub
))
colnames(acc_logist1) <- "acc"
acc_logist1$group <- "logist"
acc_logist1$group[101:200] <- "EN + logist"
acc_logist1$group[201:300] <- "iTwiner + logist"
acc_logist1<- acc_logist1 %>% mutate_if(is.character,factor)
acc_logist1$group <- ordered(acc_logist1$group, levels = c("logist", "EN + logist","iTwiner + logist"))

acc_logist1$dataset <- "DATASET1"






rf1 <- acc[5,]
rf_en1 <- acc_enplus[5,]
rf_iTwiner1 <- acc_tcoxplus[5,]

acc_rf1 <- as.data.frame(c(rf1,rf_en1, rf_iTwiner1
                             #,rf_hub
))
colnames(acc_rf1) <- "acc"
acc_rf1$group <- "rf"
acc_rf1$group[101:200] <- "EN + rf"
acc_rf1$group[201:300] <- "iTwiner + rf"
acc_rf1<- acc_rf1 %>% mutate_if(is.character,factor)
acc_rf1$group <- ordered(acc_rf1$group, levels = c("rf", "EN + rf","iTwiner + rf"))

acc_rf1$dataset <- "DATASET1"





```




# final results

- Plots comparing data partitions after running chunk bellow (line 208) for the three distinct datasets

```{r}
# Libraries
library(ggplot2)
library(dplyr)
library(forcats)
library(hrbrthemes)
library(viridis)

# Load dataset from github
data_dt <- rbind(acc_dt1,acc_dt2,acc_dt3)


p <- ggplot(data_dt, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmL <- rbind(acc_svmL1,acc_svmL2,acc_svmL3)


p <- ggplot(data_svmL, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmL",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmR <- rbind(acc_svmR1,acc_svmR2,acc_svmR3)


p <- ggplot(data_svmR, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmR",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )






data_logis <- rbind(acc_logist1,acc_logist2,acc_logist3)


p <- ggplot(data_logis, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Logistic",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )







data_rf <- rbind(acc_rf1,acc_rf2,acc_rf3)


p <- ggplot(data_rf, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Random Forest",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )


```

