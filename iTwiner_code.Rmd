---
title: "iTwiner regularizer"
author: "Carolina Peixoto"
output: 
  html_document:
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: inline
params:
  seed: !r 2010
  nfolds: !r 10
  nsample: 30
---

```{r}
set.seed(params$seed)
```

# Install packages

## Required libraries
```{r message = FALSE}
library(funModeling) 
library(tidyverse) 
library(Hmisc)
library(biomaRt)
library(survminer)
library(glmnet)
library(glmSparseNet)
library(PRROC)
library(propagate)
library(lsa)
library(edgeR)
library(limma)
library(Glimma)
library(gplots)
library(DESeq2)
library(RColorBrewer)
library(GEOquery)
library(tibble)
library ( DESeq2 )
library(NMF)
library(ISLR)
library(tree)
library(readxl)
# library(ggbiplot)
library(caret)
library(rpart)
library(rpart.plot)
library(futile.logger)
library(ggpubr)
library(rstatix)
library(writexl)
library(pROC)
```



# Data 
## RnaSeq 
- RNAseq data from CRC patients provided by Hospital de Santa Maria (Lisbon)

```{r, message = FALSE}
rnaseq1 <- read_excel("data/rnaseq_LCosta.xlsx")
rnaseq1 <- as.data.frame(rnaseq1)

ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
hgnc_swissprot <- getBM(attributes=c('ensembl_gene_id','hgnc_symbol'),filters = 'ensembl_gene_id', values = rnaseq1$...1, mart = ensembl)
hgnc_swissprot[1:3,1:2]

hgnc_swissprot <- hgnc_swissprot[!duplicated(hgnc_swissprot$ensembl_gene_id), ]


rnaseq1 <- rnaseq1[rnaseq1$...1 %in% 
                              hgnc_swissprot$ensembl_gene_id,]

rnaseq1$genes <- hgnc_swissprot$hgnc_symbol
rnaseq1 <- rnaseq1[!duplicated(rnaseq1$genes), ]
which(is.na(rnaseq1[,101]))
# rnaseq <- rnaseq[-38532,]
rownames(rnaseq1) <- rnaseq1$genes
rnaseq1 <- rnaseq1[,-c(1,101)]
rnaseq1 <- t(rnaseq1)
which(colnames(rnaseq1)=="")
rnaseq1 <- rnaseq1[,-1599]
rnaseq1 <- as.data.frame(rnaseq1)
rnaseq1$row <- rownames(rnaseq1)
dim(rnaseq1)


rnaseq2 <- read_excel("data/rnaseq_illumina.xlsx")
rnaseq2 <- as.data.frame(rnaseq2)

ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
hgnc_swissprot <- getBM(attributes=c('ensembl_gene_id','hgnc_symbol'),filters = 'ensembl_gene_id', values = rnaseq2$...1, mart = ensembl)
hgnc_swissprot[1:3,1:2]

hgnc_swissprot <- hgnc_swissprot[!duplicated(hgnc_swissprot$ensembl_gene_id), ]


rnaseq2 <- rnaseq2[rnaseq2$...1 %in% 
                              hgnc_swissprot$ensembl_gene_id,]

rnaseq2$genes <- hgnc_swissprot$hgnc_symbol
rnaseq2 <- rnaseq2[!duplicated(rnaseq2$genes), ]
which(is.na(rnaseq2[,88]))
# rnaseq <- rnaseq[-38532,]
rownames(rnaseq2) <- rnaseq2$genes
rnaseq2 <- rnaseq2[,-c(1,88)]
rnaseq2 <- t(rnaseq2)
which(colnames(rnaseq2)=="")
rnaseq2 <- rnaseq2[,-1599]
rnaseq2 <- as.data.frame(rnaseq2)
rnaseq2$row <- rownames(rnaseq2)
dim(rnaseq2)
```


```{r}
rnaseq <- rbind(rnaseq1,rnaseq2)
rnaseq1 <- rnaseq[!duplicated(rnaseq$row),]
rnaseq1 <- rnaseq1[,-39475]
rnaseq1 <- rnaseq1[ order(row.names(rnaseq1)), ]
```


## Clinic 

- clinical data from CRC patients provided by Hospital de Santa Maria (Lisbon) 

```{r, message = FALSE}
DATASET1 <- read_excel("data/DATASET1NEW_illumina.xlsx")
DATASET1 <- DATASET1[ order(DATASET1$ID), ]
rownames(DATASET1) <- DATASET1$ID

rnaseq1 <- as.data.frame(rnaseq1[rownames(rnaseq1) %in% 
                         rownames(DATASET1),])

DATASET1 <- as.data.frame(DATASET1[rownames(DATASET1) %in% 
                         rownames(rnaseq1),])


clinic1 <- DATASET1[,-c(1,8,9)]
rownames(clinic1) <- DATASET1$ID

```

- Divide data into 3 smaller datasets 

```{r}
set.seed(2010)
# imbalanced data
prop.table(table(DATASET1$class))

df_p <- DATASET1[which(DATASET1$class == "P"),]
df_pm <- DATASET1[which(DATASET1$class == "Pm"),]
### setting negative counts to be same as positive counts - so that the data is balanced
nsample <- params$nsample
pick_negative <- sample(df_p$ID, nsample)
df_p1f <- df_p[df_p$ID %in% pick_negative, ] 
df_p2 <- subset(df_p,!(ID %in% pick_negative))

nsample <- 25
pick_negative <- sample(df_p2$ID, nsample)
df_p2f <- df_p2[df_p2$ID %in% pick_negative, ] 
df_p3f <- subset(df_p2,!(ID %in% pick_negative))


df1 <- rbind(df_p1f,df_pm)
df2 <- rbind(df_p2f,df_pm)
df3 <- rbind(df_p3f,df_pm)

dim(df1)
dim(df2)
dim(df3)
table(df1$class)
table(df2$class)
table(df3$class)


clinic1_bal <- df1[,-c(1,8,9)]
datasurv1 <- as.data.frame(df1[,8:9])
rownames(clinic1_bal) <- df1$ID
rownames(datasurv1) <- df1$ID

clinic2_bal <- df2[,-c(1,8,9)]
datasurv2 <- as.data.frame(df2[,8:9])
rownames(clinic2_bal) <- df2$ID
rownames(datasurv2) <- df2$ID

clinic3_bal <- df3[,-c(1,8,9)]
datasurv3 <- as.data.frame(df3[,8:9])
rownames(clinic3_bal) <- df3$ID
rownames(datasurv3) <- df3$ID
```

# Analysis

- Run following code for each dataset used (df1,df2,df3) 

## DATASET 1 

### DATA
- Here we give the example for dataset 1
(to test other datasets replace x to the following dfx, datasetx_bal, and clinicx_bal)
ps: don't forget to change save.image("~resultsx_2010.RData") to save the data of each dataset


```{r}
load("~/CRC_LCosta/results/results1_2010_final.RData")
DATASET1_bal <- df1
DATASET1 <- DATASET1_bal
clinic1 <- clinic1_bal
```

- Split dataset in two groups for classification: 
  -- P -> non-metastatic (CLASS = 1)
  -- PM -> metastatic (CLASS = 0)

```{r, warning=FALSE,message=FALSE}
# primM <- DATASET1 %>%
#   filter(str_detect(class, "m"))
# rownames(primM) <- primM$ID
# primN <- DATASET1 %>%
#   filter(!str_detect(class, "Pm"))
# rownames(primN) <- primN$ID
# 
# clinic_prim <- DATASET1
# 
# rnaprimM <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primM),]
# 
# rnaprimN <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primN),]
# 
# rnaprim <- rbind(rnaprimM,rnaprimN)
```

- removing variables with sd=0

```{r, warning=FALSE,message=FALSE}
# xmet <- rnaprimM [,sapply(seq(ncol(rnaprimM)), function(ix) {sd(rnaprimM[,ix])}) != 0] 
# xnon <- rnaprimN[,sapply(seq(ncol(rnaprimN)), function(ix) {sd(rnaprimN[,ix])}) != 0] 
# 
# xmet_less <- xmet[,which(colnames(xmet) %in% colnames(xnon))]
# xnon_less <- xnon[,which(colnames(xnon) %in% colnames(xmet))]
# 
# # normalizing data
# xmet_norm <- scale(log2(xmet_less+1)) 
# xnon_norm <- scale(log2(xnon_less+1)) 
# 
# xdataT <- rbind(xmet_less,xnon_less)
# xdataT <- xdataT[, !sapply(xdataT, function(x) { sd(x) == 0} )]
# xdataT <- xdataT[ order(row.names(xdataT)), ]
# 
# 
# 
# rm(xmet,xmet_less,xnon,xnon_less,rnaprimM,rnaprimN)
```

- weight vector that penalizes genes with greater distances between Pm and P correlation matrices - TWINER

```{r, warning=FALSE,message=FALSE}
# #xmet_cor <- Matrix(cor(xmet_norm), sparse = TRUE)
# xmet_cor <- cor(xmet_norm)
# #xmet_cor <- as.data.frame(xmet_cor)
# xnon_cor <- cor(xnon_norm)
# #xnon_cor <- as.data.frame(xnon_cor)
# 
# # angular distance
# ang_weight <- vector()
# for (i in 1:dim(xmet_cor)[2]){ 
# ang_weight[i] <- acos(cosine(xmet_cor[,i],xnon_cor[,i]))/pi
# }
# 
# ## normalized weights
# 
# weights <- ang_weight / max(ang_weight)
# hist(weights,main="w")
# 
# 
# pen_weight1 <- 1 / weights
# hist(pen_weight1, main="1 / w")
# 
# rm(xmet_cor,xnon_cor)
```

### Exploratory analysis

- All dataset x

```{r}
clinical <- as.data.frame(clinic1_bal)


basic_eda <- function(clinical)
{
  glimpse(clinical)
  #df_Status(clinical)
  freq(clinical) 
  profiling_num(clinical)
  plot_num(clinical)
  describe(clinic1)
}
basic_eda(clinical)

a <- na.omit(clinical$Age)
mean(a)
``` 

- Only patients that do not metastasize

```{r}
clinical_p <- clinic1_bal %>%
  filter(!str_detect(class, "Pm"))


basic_eda <- function(clinical_p)
{
  glimpse(clinical_p)
  #df_Status(clinical_p)
  freq(clinical_p) 
  profiling_num(clinical_p)
  plot_num(clinical_p)
  describe(clinical_p)
}
basic_eda(clinical_p)

a <- na.omit(clinical_p$Age)
mean(a)
```

- Only patients that do metastasize

```{r}
clinical_Pm <- clinic1_bal%>%
  filter(str_detect(class, "Pm"))


basic_eda <- function(clinical_Pm)
{
  glimpse(clinical_Pm)
  #df_Status(clinical_Pm)
  freq(clinical_Pm) 
  profiling_num(clinical_Pm)
  plot_num(clinical_Pm)
  describe(clinical_Pm)
}
basic_eda(clinical_Pm)

a <- na.omit(clinical_Pm$Age)
mean(a)

```

- Statistic differences between patients groups regarding several variables

```{r}
clinical_factor <- clinic1_bal
clinical_factor <- clinical_factor %>%
  mutate_if(sapply(clinical_factor, is.character), as.factor)
#clinical_factor <- na.omit(clinical_factor)

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  organ), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Sex), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

clinical_factor1 <- clinical_factor %>%
  filter(!str_detect(sidedness, "rectum"))

ggplot(data = clinical_factor1) + 
  geom_bar(mapping = aes(x = class, fill =  sidedness), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Stage), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4", "#000080"))


clinical_factor %>%
  ggplot( aes(x=Age, fill=class)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) 
    labs(fill="")

```

```{r}
stat_data_organ <- table(clinical_factor$class,clinical_factor$organ)
#fazer plot(...)
fisher.test(stat_data_organ)

stat_data_sex <- table(clinical_factor$class,clinical_factor$Sex)
fisher.test(stat_data_sex)

stat_data_stage <- table(clinical_factor$class,clinical_factor$Stage)
fisher.test(stat_data_stage)

stat_data_side <- table(clinical_factor$class,clinical_factor$sidedness)
fisher.test(stat_data_side)



hist(clinical_factor$Age[clinical_factor$class=="P"])
hist(clinical_factor$Age[clinical_factor$class=="Pm"])

tapply(clinical_factor$Age,clinical_factor$class, summary)
t.test(Age ~ class, clinical_factor)
```


### Survival analysis

#### Stage

```{r}
data <- merge(datasurv1, clinical, by="row.names")

fit <- survfit(Surv(time, Status) ~ Stage, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ Stage, data = data)
surv.stage

```


#### Class - PM vs. P

```{r}

fit <- survfit(Surv(time, Status) ~ class, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ class, data = data)
surv.stage

```


#### Sidedness

```{r}
newdata <- data[-which(data$sidedness == "rectum"),]
fit <- survfit(Surv(time, Status) ~ sidedness, data = newdata)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = newdata, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ sidedness, data = newdata)
surv.stage

```


### DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                         rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_d1.xlsx")

top100_deg <- rownames(genes_deg[1:100,])
# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)
top100_high <- rownames(high[1:100,])

#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)
top100_low <- rownames(low[1:100,])
```

### Classification

- In this work we tested 3 different types of classification: 1) Classification without regularization based on DEGs; 2) Classification with regularization (EN and iTwiner); 3) Classification without regularization based on genes selected by regularized logistic regression;

```{r}
xdata.raw <- xdataT

# keep features with standard deviation > 0
xdata <- xdata.raw[,sapply(seq(ncol(xdata.raw)), function(ix) {sd(xdata.raw[,ix])}) != 0]

ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

# ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```


#### 1) Classification without regularization based on DEGs

Five classifiers were used: Decision trees, linear and radial support vector machines, logistic regression and random forest

- Lets pick up the 50 deferentially expressed genes with lowest pvalue found above

```{r}
xdata <- xdataT[,top100_deg[1:50]]

nomesgenes <- colnames(xdata)
colnames(xdata) <- paste0("Var", 1:50)
colnames(ydata) <- c("class","row")
xdata$type <- as.factor(ydata$class)

#xdata <- xdata[colMeans(xdata == 0) <= 0.6] #delete genes that have null values in at least 60% of the samples

```

- Test the different classifiers 100 times to obtain median values for the measures of model performance such as accuracy, misclassification, sensitivity and specificity, among others

```{r, echo=FALSE,warning=FALSE,message=FALSE}

times_boot <- 100

acc <- matrix(0,5,times_boot)
kappa<- matrix(0,5,times_boot)
sensitivity<- matrix(0,5,times_boot)
specificity <- matrix(0,5,times_boot)
miscl <- matrix(0,5,times_boot)
fpos <- matrix(0,5,times_boot)
fneg <- matrix(0,5,times_boot)
auc <- matrix(0,5,times_boot)

acc_train <- matrix(0,5,times_boot)
kappa_train<- matrix(0,5,times_boot)
sensitivity_train<- matrix(0,5,times_boot)
specificity_train <- matrix(0,5,times_boot)
miscl_train <- matrix(0,5,times_boot)
fpos_train <- matrix(0,5,times_boot)
fneg_train <- matrix(0,5,times_boot)
auc_train <- matrix(0,5,times_boot)

ids_fn_tree1 <- vector("list")
ids_fn_svmL1 <- vector("list")
ids_fn_svmR1 <- vector("list")
ids_fn_logist1 <- vector("list")
ids_fn_rf1 <- vector("list")

ids_fp_tree1 <- vector("list")
ids_fp_svmL1 <- vector("list")
ids_fp_svmR1 <- vector("list")
ids_fp_logist1 <- vector("list")
ids_fp_rf1 <- vector("list")


run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)


  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  training <- xdata[ixs$train,]
  testing <- xdata[ixs$test,]


# Classification 

## Decision tree
### Fit the model on the training set

control <- rpart.control(minsplit = 4)

model2 <- rpart(type~., data = training, method = 'class', control = control)

  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[1,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[1,i] <- t[1,2]+t[2,1]
  fneg_train[1,i] <- t[2,1]
  ###


  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[1,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[1,i] <- length(listafp)
  fneg[1,i] <- length(listafn)
  ids_fn_tree1[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1[[i]] <- rownames(testing[listafp,])


  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[1,i] <- result[["overall"]][["Accuracy"]]
  kappa[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[1,i] <- result[["byClass"]][["Specificity"]]
  miscl[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[2,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[2,i] <- t[1,2]+t[2,1]
  fneg_train[2,i] <- t[2,1]
  
  
  # Test
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[2,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[2,i] <- length(listafp)
  fneg[2,i] <- length(listafn)
  ids_fn_svmL1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[2,i] <- result[["overall"]][["Accuracy"]]
  kappa[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[2,i] <- result[["byClass"]][["Specificity"]]
  miscl[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[3,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[3,i] <- t[1,2]+t[2,1]
  fneg_train[3,i] <- t[2,1]
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[3,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    }  else {
      listafn <- c(listafn, a)
    }
  }

  fpos[3,i] <- length(listafp)
  fneg[3,i] <- length(listafn)
  ids_fn_svmR1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[3,i] <- result[["overall"]][["Accuracy"]]
  kappa[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[3,i] <- result[["byClass"]][["Specificity"]]
  miscl[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


logist <- train(type ~., data = training, method = "LogitBoost",
                trControl=trainControl("cv", number = 10),
                tuneLength = 10)

  # Train
  pred <- predict(logist, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[4,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[4,i] <- t[1,2]+t[2,1]
  fneg_train[4,i] <- t[2,1]
  
  #Test
  
  pred <- predict(logist,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[4,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[4,i] <- length(listafp)
  fneg[4,i] <- length(listafn)
  ids_fn_logist1[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[4,i] <- result[["overall"]][["Accuracy"]]
  kappa[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[4,i] <- result[["byClass"]][["Specificity"]]
  miscl[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # Train
  pred <- predict(model.rf, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[5,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[5,i] <- t[1,2]+t[2,1]
  fneg_train[5,i] <- t[2,1]
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[5,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[5,i] <- length(listafp)
  fneg[5,i] <- length(listafn)
  ids_fn_rf1[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)


  acc[5,i] <- result[["overall"]][["Accuracy"]]
  kappa[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[5,i] <- result[["byClass"]][["Specificity"]]
  miscl[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing,a)
}

```



##### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_train[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_train[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_train[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_train[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_train[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_train[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_train[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_train[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_train[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_train[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_train[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_train[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_train[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_train[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_train[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_train[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_train[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_train[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_train[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_train[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_train[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_train[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_train[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_train[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_train[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_train[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_train[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_train[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_train[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_train[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



##### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



#### 2) Classification with regularization (EN and iTwiner)

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID
# 
# # ydata.raw$class <- c(rep(0,28),rep(1,34))
#  
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw)
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 1000

nvar_selected_1 <- matrix(0,2,times_boot)

var_selected_en1 <- vector("list")
var_selected_iTwiner1 <- vector("list")

acc_cox_tr <- matrix(0,2,times_boot)
acc_cox_tes <- matrix(0,2,times_boot)
kappa_cox_tr <- matrix(0,2,times_boot)
kappa_cox_tes <- matrix(0,2,times_boot)
sensitivity_cox_tr <- matrix(0,2,times_boot)
sensitivity_cox_tes <- matrix(0,2,times_boot)
specificity_cox_tr <- matrix(0,2,times_boot)
specificity_cox_tes <- matrix(0,2,times_boot)
miscl_cox_tr <- matrix(0,2,times_boot)
miscl_cox_tes <- matrix(0,2,times_boot)
auc_cox_tr <- matrix(0,2,times_boot)
auc_cox_tes <- matrix(0,2,times_boot)


fpos_reg_tr <- matrix(0,2,times_boot)
fpos_reg_ts <- matrix(0,2,times_boot)
fneg_reg_tr <- matrix(0,2,times_boot)
fneg_reg_ts <- matrix(0,2,times_boot)

ids_fn_en <- vector("list")
ids_fn_iTwiner <- vector("list")


ids_fp_en <- vector("list")
ids_fp_iTwiner <- vector("list")

run = 1000

i=1
l1=0
while(l1 < 100){
  
  print(l1)
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  # Classification by sparse logistic regression
  
  ## with the elastic net (EN) penalty
  
  fit_EN1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.2,
                       #foldid=my_foldid,
                       type.measure="mse")
  
  var_selected <- which(fit_EN1$glmnet.fit$beta[,which(fit_EN1$cvm == min(fit_EN1$cvm))] != 0)
  
  nvar_selected_1[1,i] <- length(var_selected)
  
  
  var_selected_en1[[i]] <- names(var_selected)
  
  
  
  if (length(var_selected) > 1){
    
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("en train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[1,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[1,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[1,i] <- t[2,1]
        
        rm(var_selected,resp_train,t,result,a)
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("en pred ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[1,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[1,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }

    fpos_reg_ts[1,i] <- length(listafp)
    fneg_reg_ts[1,i] <- length(listafn)
    ids_fn_en[[i]] <- rownames(xtest[listafn,])
    ids_fp_en[[i]] <- rownames(xtest[listafp,])
    
    
    print("EN")} else{
      print("EN não selecionou variaveis")
    }
  
  rm(pred,t,result)
  
  
  i=i+1
  
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  
  l1 <- length(which(acc_cox_tr[1,]!=0))
  
}
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
i=1
l2=0
while(l2 < 100){
  
  print(i)
  print(l2)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  ## with network information - iTwiner
  
  fit_tco1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.05 ,
                        #foldid=my_foldid,
                        penalty.factor = pen_weight1,
                        type.measure="mse")
  
  var_selected <- which(fit_tco1$glmnet.fit$beta[,which(fit_tco1$cvm == min(fit_tco1$cvm))] != 0)
  
  nvar_selected_1[2,i] <- length(var_selected)
  
  
  var_selected_iTwiner1[[i]] <- names(var_selected)
  
  if (length(var_selected) > 1){
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("iTwiner train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[2,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[2,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[2,i] <- t[2,1]
        rm(var_selected,resp_train,t,result,a)
        
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("iTwiner test ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[2,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[2,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }
    
    fpos_reg_ts[2,i] <- length(listafp)
    fneg_reg_ts[2,i] <- length(listafn)
    ids_fn_iTwiner[[i]] <- rownames(xtest[listafn,])
    ids_fp_iTwiner[[i]] <- rownames(xtest[listafp,])
    
    
    
    print("iTwiner")
    
  } else{
    print("iTwiner não correu")
  }
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  l2 <- length(which(acc_cox_tr[2,]!=0))
  i=i+1
}

```

##### Measures of model performance

```{r}
runs_en_tr <- which(acc_cox_tr[1,]!=0)
runs_itw_tr <- which(acc_cox_tr[2,]!=0)

runs_en_ts <- which(acc_cox_tes[1,]!=0)
runs_itw_ts <- which(acc_cox_tes[2,]!=0)
```

- number variables selected

```{r}
# median number of variables selected
nvar_en <- nvar_selected_1[1,]
nvar_en <- nvar_en[runs_en_tr]
mean(nvar_en)
median(nvar_en)
sd(nvar_en)

nvar_tw <- nvar_selected_1[2,]
nvar_tw <- nvar_tw[runs_itw_tr]
mean(nvar_tw)
median(nvar_tw)
sd(nvar_tw)
```

- Accuracy
```{r}
# EN train
acc_cox_tr_EN <- acc_cox_tr[1,]
acc_cox_tr_EN <- acc_cox_tr_EN[runs_en_tr]
#hist(acc_cox_tr_EN)
mean(acc_cox_tr_EN)  
median(acc_cox_tr_EN)
sd(acc_cox_tr_EN)

# EN test
acc_cox_tes_EN <- acc_cox_tes[1,]
acc_cox_tes_EN <- acc_cox_tes_EN[runs_en_ts]
#hist(acc_cox_tes_EN)
mean(acc_cox_tes_EN)
median(acc_cox_tes_EN)
sd(acc_cox_tes_EN)

#iTwiner train
acc_cox_tr_iTwiner <- acc_cox_tr[2,]
acc_cox_tr_iTwiner <- acc_cox_tr_iTwiner[runs_itw_tr]
#hist(acc_cox_tr_iTwiner)
mean(acc_cox_tr_iTwiner)
median(acc_cox_tr_iTwiner)
sd(acc_cox_tr_iTwiner)

#iTwiner test
acc_cox_tes_iTwiner <- acc_cox_tes[2,]
acc_cox_tes_iTwiner <- acc_cox_tes_iTwiner[runs_itw_ts]
#hist(acc_cox_tes_iTwiner)
mean(acc_cox_tes_iTwiner)
median(acc_cox_tes_iTwiner)
sd(acc_cox_tes_iTwiner)
```
- miscl

```{r}
# EN train
miscl_cox_tr_EN <- miscl_cox_tr[1,]
miscl_cox_tr_EN <- miscl_cox_tr_EN[runs_en_tr]
mean(miscl_cox_tr_EN)  
median(miscl_cox_tr_EN)
sd(miscl_cox_tr_EN)

# EN test
miscl_cox_tes_EN <- miscl_cox_tes[1,]
miscl_cox_tes_EN <- miscl_cox_tes_EN[runs_en_ts]
mean(miscl_cox_tes_EN)
median(miscl_cox_tes_EN)
sd(miscl_cox_tes_EN)

#iTwiner train
miscl_cox_tr_iTwiner <- miscl_cox_tr[2,]
miscl_cox_tr_iTwiner <- miscl_cox_tr_iTwiner[runs_itw_tr]
mean(miscl_cox_tr_iTwiner)
median(miscl_cox_tr_iTwiner)
sd(miscl_cox_tr_iTwiner)

#iTwiner test
miscl_cox_tes_iTwiner <- miscl_cox_tes[2,]
miscl_cox_tes_iTwiner <- miscl_cox_tes_iTwiner[runs_itw_ts]
mean(miscl_cox_tes_iTwiner)
median(miscl_cox_tes_iTwiner)
sd(miscl_cox_tes_iTwiner)
```

- False Neg

```{r}
#EN
fneg_reg_en_train <- fneg_reg_tr[1,runs_en_tr]
mean(fneg_reg_en_train)
median(fneg_reg_en_train)
sd(fneg_reg_en_train)

fneg_reg_en_test <- fneg_reg_ts[1,runs_en_ts]
mean(fneg_reg_en_test)
median(fneg_reg_en_test)
sd(fneg_reg_en_test)

#iTwiner
fneg_reg_iTwiner_train <- fneg_reg_tr[2,runs_itw_tr]
mean(fneg_reg_iTwiner_train)
median(fneg_reg_iTwiner_train)
sd(fneg_reg_iTwiner_train)

fneg_reg_iTwiner_test <- fneg_reg_ts[2,runs_itw_ts]
mean(fneg_reg_iTwiner_test)
median(fneg_reg_iTwiner_test)
sd(fneg_reg_iTwiner_test)
```

- sensitivity

```{r}
# EN train
sensitivity_cox_tr_EN <- sensitivity_cox_tr[1,]
sensitivity_cox_tr_EN <- sensitivity_cox_tr_EN[runs_en_tr]
mean(sensitivity_cox_tr_EN)  
median(sensitivity_cox_tr_EN)
sd(sensitivity_cox_tr_EN)

# EN test
sensitivity_cox_tes_EN <- sensitivity_cox_tes[1,]
sensitivity_cox_tes_EN <- sensitivity_cox_tes_EN[runs_en_ts]
mean(sensitivity_cox_tes_EN)
median(sensitivity_cox_tes_EN)
sd(sensitivity_cox_tes_EN)

#iTwiner train
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr[2,]
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr_iTwiner[runs_itw_tr]
mean(sensitivity_cox_tr_iTwiner)
median(sensitivity_cox_tr_iTwiner)
sd(sensitivity_cox_tr_iTwiner)

#iTwiner test
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes[2,]
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes_iTwiner[runs_itw_ts]
mean(sensitivity_cox_tes_iTwiner)
median(sensitivity_cox_tes_iTwiner)
sd(sensitivity_cox_tes_iTwiner)
```

- specificity

```{r}
# EN train
specificity_cox_tr_EN <- specificity_cox_tr[1,]
specificity_cox_tr_EN <- specificity_cox_tr_EN[runs_en_tr]
mean(specificity_cox_tr_EN)  
median(specificity_cox_tr_EN)
sd(specificity_cox_tr_EN)

# EN test
specificity_cox_tes_EN <- specificity_cox_tes[1,]
specificity_cox_tes_EN <- specificity_cox_tes_EN[runs_en_ts]
mean(specificity_cox_tes_EN)
median(specificity_cox_tes_EN)
sd(specificity_cox_tes_EN)

#iTwiner train
specificity_cox_tr_iTwiner <- specificity_cox_tr[2,]
specificity_cox_tr_iTwiner <- specificity_cox_tr_iTwiner[runs_itw_tr]
mean(specificity_cox_tr_iTwiner)
median(specificity_cox_tr_iTwiner)
sd(specificity_cox_tr_iTwiner)

#iTwiner test
specificity_cox_tes_iTwiner <- specificity_cox_tes[2,]
specificity_cox_tes_iTwiner <- specificity_cox_tes_iTwiner[runs_itw_ts]
mean(specificity_cox_tes_iTwiner)
median(specificity_cox_tes_iTwiner)
sd(specificity_cox_tes_iTwiner)
```


- auc

```{r}
# EN train
auc_cox_tr_EN <- auc_cox_tr[1,]
auc_cox_tr_EN <- auc_cox_tr_EN[runs_en_tr]
mean(auc_cox_tr_EN)  
median(auc_cox_tr_EN)
sd(auc_cox_tr_EN)

# EN test
auc_cox_tes_EN <- auc_cox_tes[1,]
auc_cox_tes_EN <- auc_cox_tes_EN[runs_en_ts]
mean(auc_cox_tes_EN)
median(auc_cox_tes_EN)
sd(auc_cox_tes_EN)

#iTwiner train
auc_cox_tr_iTwiner <- auc_cox_tr[2,]
auc_cox_tr_iTwiner <- auc_cox_tr_iTwiner[runs_itw_tr]
mean(auc_cox_tr_iTwiner)
median(auc_cox_tr_iTwiner)
sd(auc_cox_tr_iTwiner)

#iTwiner test
auc_cox_tes_iTwiner <- auc_cox_tes[2,]
auc_cox_tes_iTwiner <- auc_cox_tes_iTwiner[runs_itw_ts]
mean(auc_cox_tes_iTwiner)
median(auc_cox_tes_iTwiner)
sd(auc_cox_tes_iTwiner)
```





- Names of genes selected

Variables always selected
```{r}
var_selected_alw_select_en <- var_selected_en1[runs_en_ts]
var_selected_alw_select_en1 <-  Reduce(intersect,var_selected_alw_select_en)
print(paste("variables always selected by EN = ",length(var_selected_alw_select_en1)))

var_selected_alw_select_iTwiner <- var_selected_iTwiner1[runs_itw_ts]
var_selected_alw_select_iTwiner1 <-  Reduce(intersect,var_selected_alw_select_iTwiner)
print(paste("variables always selected by iTwiner = ",length(var_selected_alw_select_iTwiner1)))
```

Variables selected in 50 bootstrap samples
```{r}
l = length(var_selected_alw_select_en)
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <-  subset(var_selected_50_select_en, Freq > 0.50*l)
print(paste("variables selected 50% by EN = ",length(var_selected_50_select_en$Var1)))
var_selected_50_select_en$Var1
# 
l = length(var_selected_alw_select_iTwiner)
var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <-  subset(var_selected_50_select_iTwiner, Freq > 0.50*l)
print(paste("variables selected 50% by iTwiner = ",length(var_selected_50_select_iTwiner$Var1)))
var_selected_50_select_iTwiner$Var1
```

- Select the 50 most frequent variables 

```{r}
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <- var_selected_50_select_en[order(var_selected_50_select_en$Freq, decreasing = T),]
hist(var_selected_50_select_en$Freq)
top100_en <- var_selected_50_select_en[1:100,]
top100_en <- top100_en$Var1
top50_en <- top100_en[1:50]
top100_en <- as.data.frame(top100_en)
write_xlsx(top100_en,"List_top100_en_d1.xlsx")

var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <- var_selected_50_select_iTwiner[order(var_selected_50_select_iTwiner$Freq, decreasing = T),]
hist(var_selected_50_select_iTwiner$Freq)
top100_itw <- var_selected_50_select_iTwiner[1:100,]
top100_itw <- top100_itw$Var1
top50_itw <- top100_itw[1:50]
top100_itw <- as.data.frame(top100_itw)
write_xlsx(top100_itw,"List_top100_itw_d1.xlsx")
```

variables in common between EN and iTwiner

```{r}
common_var_selected_50_en_iTwiner <- var_selected_50_select_iTwiner$Var1[which(var_selected_50_select_iTwiner$Var1 %in% var_selected_50_select_en$Var1)]
length(common_var_selected_50_en_iTwiner)
common_var_selected_50_en_iTwiner
```

- Variables selected by EN and iTwiner that are DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]

nomesgenes <- c(as.vector(top50_en),as.vector(top50_itw))
xdata <- xdata[,nomesgenes]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                 rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                               rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_enitw_d1.xlsx")

# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)


#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)

```










#### 3) Classification based on genes selected by regularized logistic regression

##### EN + Classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_en)
xdata_en <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_en)
colnames(xdata_en) <- paste0("Var", 1:50)
xdata_en$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_enplus <- matrix(0,5,times_boot)
kappa_enplus<- matrix(0,5,times_boot)
sensitivity_enplus<- matrix(0,5,times_boot)
specificity_enplus <- matrix(0,5,times_boot)
miscl_enplus <- matrix(0,5,times_boot)
fpos_enplus <- matrix(0,5,times_boot)
fneg_enplus <- matrix(0,5,times_boot)
auc_enplus <- matrix(0,5,times_boot)

acc_enplus_train <- matrix(0,5,times_boot)
kappa_enplus_train<- matrix(0,5,times_boot)
sensitivity_enplus_train<- matrix(0,5,times_boot)
specificity_enplus_train <- matrix(0,5,times_boot)
miscl_enplus_train <- matrix(0,5,times_boot)
fpos_enplus_train <- matrix(0,5,times_boot)
fneg_enplus_train <- matrix(0,5,times_boot)
auc_enplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_enplus <- vector("list")
ids_fn_svmL1_enplus <- vector("list")
ids_fn_svmR1_enplus <- vector("list")
ids_fn_logist1_enplus <- vector("list")
ids_fn_rf1_enplus <- vector("list")

ids_fp_tree1_enplus <- vector("list")
ids_fp_svmL1_enplus <- vector("list")
ids_fp_svmR1_enplus <- vector("list")
ids_fp_logist1_enplus <- vector("list")
ids_fp_rf1_enplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_en[ixs$train,]
  testing <- xdata_en[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[1,i] <- length(listafp)
  fneg_enplus[1,i] <- length(listafn)
  ids_fn_tree1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <-  predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[2,i] <- length(listafp)
  fneg_enplus[2,i] <- length(listafn)
  ids_fn_svmL1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[3,i] <- length(listafp)
  fneg_enplus[3,i] <- length(listafn)
  ids_fn_svmR1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[4,i] <- length(listafp)
  fneg_enplus[4,i] <- length(listafn)
  ids_fn_logist1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[5,i] <- length(listafp)
  fneg_enplus[5,i] <- length(listafn)
  ids_fn_rf1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_enplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}

```


###### Measures of model performance train


- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity
```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg
```{r}
# fneg
fneg_trees <- fneg_enplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_enplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

##### iTwiner + classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_itw)
xdata_iTwiner <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_iTwiner)
colnames(xdata_iTwiner) <- paste0("Var", 1:50)
xdata_iTwiner$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_tcoxplus <- matrix(0,5,times_boot)
kappa_tcoxplus<- matrix(0,5,times_boot)
sensitivity_tcoxplus<- matrix(0,5,times_boot)
specificity_tcoxplus <- matrix(0,5,times_boot)
miscl_tcoxplus <- matrix(0,5,times_boot)
fpos_tcoxplus <- matrix(0,5,times_boot)
fneg_tcoxplus <- matrix(0,5,times_boot)
auc_tcoxplus <- matrix(0,5,times_boot)

acc_tcoxplus_train <- matrix(0,5,times_boot)
kappa_tcoxplus_train<- matrix(0,5,times_boot)
sensitivity_tcoxplus_train<- matrix(0,5,times_boot)
specificity_tcoxplus_train <- matrix(0,5,times_boot)
miscl_tcoxplus_train <- matrix(0,5,times_boot)
fpos_tcoxplus_train <- matrix(0,5,times_boot)
fneg_tcoxplus_train <- matrix(0,5,times_boot)
auc_tcoxplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_tcoxplus <- vector("list")
ids_fn_svmL1_tcoxplus <- vector("list")
ids_fn_svmR1_tcoxplus <- vector("list")
ids_fn_logist1_tcoxplus <- vector("list")
ids_fn_rf1_tcoxplus <- vector("list")

ids_fp_tree1_tcoxplus <- vector("list")
ids_fp_svmL1_tcoxplus <- vector("list")
ids_fp_svmR1_tcoxplus <- vector("list")
ids_fp_logist1_tcoxplus <- vector("list")
ids_fp_rf1_tcoxplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_iTwiner[ixs$train,]
  testing <- xdata_iTwiner[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[1,i] <- length(listafp)
  fneg_tcoxplus[1,i] <- length(listafn)
  ids_fn_tree1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[2,i] <- length(listafp)
  fneg_tcoxplus[2,i] <- length(listafn)
  ids_fn_svmL1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[3,i] <- length(listafp)
  fneg_tcoxplus[3,i] <- length(listafn)
  ids_fn_svmR1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[4,i] <- length(listafp)
  fneg_tcoxplus[4,i] <- length(listafn)
  ids_fn_logist1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[5,i] <- length(listafp)
  fneg_tcoxplus[5,i] <- length(listafn)
  ids_fn_rf1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_tcoxplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}
```


###### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc
```{r}
# auc
auc_trees <- auc_tcoxplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_tcoxplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_tcoxplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```


###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_tcoxplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification
```{r}
# miscl
miscl_trees <- miscl_tcoxplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity
```{r}
# specificity
specificity_trees <- specificity_tcoxplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

```{r}
# save results

#save.image("~/results1_2010_final.RData")
```



### Data final 

```{r}
dt1 <- acc[1,]
dt_en1 <- acc_enplus[1,]
dt_iTwiner1 <- acc_tcoxplus[1,]
#dt_hub <- acc_hubplus[1,]

acc_dt1 <- as.data.frame(c(dt1,dt_en1, dt_iTwiner1
                           #,dt_hub
))
colnames(acc_dt1) <- "acc"
#acc_dt$group <- "HUB + DT"
#acc_dt$group[1:100] <- "DT"
acc_dt1$group <- "DT"
acc_dt1$group[101:200] <- "EN + DT"
acc_dt1$group[201:300] <- "iTwiner + DT"
acc_dt1<- acc_dt1 %>% mutate_if(is.character,factor)
# acc_dt$group <- ordered(acc_dt$group, levels = c("DT", "EN + DT","iTwiner + DT", "HUB + DT"))
acc_dt1$group <- ordered(acc_dt1$group, levels = c("DT", "EN + DT","iTwiner + DT"))

acc_dt1$dataset <- "DATASET1"



svmL1 <- acc[2,]
svmL_en1 <- acc_enplus[2,]
svmL_iTwiner1 <- acc_tcoxplus[2,]

acc_svmL1 <- as.data.frame(c(svmL1,svmL_en1, svmL_iTwiner1
                             #,svmL_hub
))
colnames(acc_svmL1) <- "acc"
acc_svmL1$group <- "svmL"
acc_svmL1$group[101:200] <- "EN + svmL"
acc_svmL1$group[201:300] <- "iTwiner + svmL"
acc_svmL1<- acc_svmL1 %>% mutate_if(is.character,factor)
acc_svmL1$group <- ordered(acc_svmL1$group, levels = c("svmL", "EN + svmL","iTwiner + svmL"))

acc_svmL1$dataset <- "DATASET1"




svmR1 <- acc[3,]
svmR_en1 <- acc_enplus[3,]
svmR_iTwiner1 <- acc_tcoxplus[3,]

acc_svmR1 <- as.data.frame(c(svmR1,svmR_en1, svmR_iTwiner1
                             #,svmR_hub
))
colnames(acc_svmR1) <- "acc"
acc_svmR1$group <- "svmR"
acc_svmR1$group[101:200] <- "EN + svmR"
acc_svmR1$group[201:300] <- "iTwiner + svmR"
acc_svmR1<- acc_svmR1 %>% mutate_if(is.character,factor)
acc_svmR1$group <- ordered(acc_svmR1$group, levels = c("svmR", "EN + svmR","iTwiner + svmR"))

acc_svmR1$dataset <- "DATASET1"






logist1 <- acc[4,]
logist_en1 <- acc_enplus[4,]
logist_iTwiner1 <- acc_tcoxplus[4,]

acc_logist1 <- as.data.frame(c(logist1,logist_en1, logist_iTwiner1
                             #,logist_hub
))
colnames(acc_logist1) <- "acc"
acc_logist1$group <- "logist"
acc_logist1$group[101:200] <- "EN + logist"
acc_logist1$group[201:300] <- "iTwiner + logist"
acc_logist1<- acc_logist1 %>% mutate_if(is.character,factor)
acc_logist1$group <- ordered(acc_logist1$group, levels = c("logist", "EN + logist","iTwiner + logist"))

acc_logist1$dataset <- "DATASET1"






rf1 <- acc[5,]
rf_en1 <- acc_enplus[5,]
rf_iTwiner1 <- acc_tcoxplus[5,]

acc_rf1 <- as.data.frame(c(rf1,rf_en1, rf_iTwiner1
                             #,rf_hub
))
colnames(acc_rf1) <- "acc"
acc_rf1$group <- "rf"
acc_rf1$group[101:200] <- "EN + rf"
acc_rf1$group[201:300] <- "iTwiner + rf"
acc_rf1<- acc_rf1 %>% mutate_if(is.character,factor)
acc_rf1$group <- ordered(acc_rf1$group, levels = c("rf", "EN + rf","iTwiner + rf"))

acc_rf1$dataset <- "DATASET1"





```





## DATASET 2

### DATA

```{r}
load("~/CRC_LCosta/results/results2_2010_final.RData")
DATASET1_bal <- df2
DATASET1 <- DATASET2_bal
clinic1 <- clinic2_bal
datasurv1 <- datasurv2
clinic1_bal <- clinic2_bal
```

- Split dataset in two groups for classification: 
  -- P -> non-metastatic (CLASS = 1)
  -- PM -> metastatic (CLASS = 0)

```{r, warning=FALSE,message=FALSE}
# primM <- DATASET1 %>%
#   filter(str_detect(class, "m"))
# rownames(primM) <- primM$ID
# primN <- DATASET1 %>%
#   filter(!str_detect(class, "Pm"))
# rownames(primN) <- primN$ID
# 
# clinic_prim <- DATASET1
# 
# rnaprimM <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primM),]
# 
# rnaprimN <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primN),]
# 
# rnaprim <- rbind(rnaprimM,rnaprimN)
```

- removing variables with sd=0

```{r, warning=FALSE,message=FALSE}
# xmet <- rnaprimM [,sapply(seq(ncol(rnaprimM)), function(ix) {sd(rnaprimM[,ix])}) != 0] 
# xnon <- rnaprimN[,sapply(seq(ncol(rnaprimN)), function(ix) {sd(rnaprimN[,ix])}) != 0] 
# 
# xmet_less <- xmet[,which(colnames(xmet) %in% colnames(xnon))]
# xnon_less <- xnon[,which(colnames(xnon) %in% colnames(xmet))]
# 
# # normalizing data
# xmet_norm <- scale(log2(xmet_less+1)) 
# xnon_norm <- scale(log2(xnon_less+1)) 
# 
# xdataT <- rbind(xmet_less,xnon_less)
# xdataT <- xdataT[ order(row.names(xdataT)), ]
# 
# 
# rm(xmet,xmet_less,xnon,xnon_less,rnaprimM,rnaprimN)
```

- weight vector that penalizes genes with greater distances between Pm and P correlation matrices - TWINER

```{r, warning=FALSE,message=FALSE}
# #xmet_cor <- Matrix(cor(xmet_norm), sparse = TRUE)
# xmet_cor <- cor(xmet_norm)
# #xmet_cor <- as.data.frame(xmet_cor)
# xnon_cor <- cor(xnon_norm)
# #xnon_cor <- as.data.frame(xnon_cor)
# 
# # angular distance
# ang_weight <- vector()
# for (i in 1:dim(xmet_cor)[2]){ 
# ang_weight[i] <- acos(cosine(xmet_cor[,i],xnon_cor[,i]))/pi
# }
# 
# ## normalized weights
# 
# weights <- ang_weight / max(ang_weight)
# hist(weights,main="w")
# 
# 
# pen_weight2 <- 1 / weights
# hist(pen_weight2, main="1 / w")
# 
# rm(xmet_cor,xnon_cor)
```

### Exploratory analysis

- All dataset x

```{r}
clinical <- as.data.frame(clinic1_bal)


basic_eda <- function(clinical)
{
  glimpse(clinical)
  #df_Status(clinical)
  freq(clinical) 
  profiling_num(clinical)
  plot_num(clinical)
  describe(clinic1)
}
basic_eda(clinical)

a <- na.omit(clinical$Age)
mean(a)
``` 

- Only patients that do not metastasize

```{r}
clinical_p <- clinic1_bal %>%
  filter(!str_detect(class, "Pm"))


basic_eda <- function(clinical_p)
{
  glimpse(clinical_p)
  #df_Status(clinical_p)
  freq(clinical_p) 
  profiling_num(clinical_p)
  plot_num(clinical_p)
  describe(clinical_p)
}
basic_eda(clinical_p)

a <- na.omit(clinical_p$Age)
mean(a)
```

- Only patients that do metastasize

```{r}
clinical_Pm <- clinic1_bal%>%
  filter(str_detect(class, "Pm"))


basic_eda <- function(clinical_Pm)
{
  glimpse(clinical_Pm)
  #df_Status(clinical_Pm)
  freq(clinical_Pm) 
  profiling_num(clinical_Pm)
  plot_num(clinical_Pm)
  describe(clinical_Pm)
}
basic_eda(clinical_Pm)

a <- na.omit(clinical_Pm$Age)
mean(a)

```

- Statistic differences between patients groups regarding several variables

```{r}
clinical_factor <- clinic1_bal
clinical_factor <- clinical_factor %>%
  mutate_if(sapply(clinical_factor, is.character), as.factor)
#clinical_factor <- na.omit(clinical_factor)

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  organ), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Sex), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

clinical_factor1 <- clinical_factor %>%
  filter(!str_detect(sidedness, "rectum"))

ggplot(data = clinical_factor1) + 
  geom_bar(mapping = aes(x = class, fill =  sidedness), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Stage), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4", "#000080"))


clinical_factor %>%
  ggplot( aes(x=Age, fill=class)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) 
    labs(fill="")

```

```{r}
stat_data_organ <- table(clinical_factor$class,clinical_factor$organ)
#fazer plot(...)
fisher.test(stat_data_organ)

stat_data_sex <- table(clinical_factor$class,clinical_factor$Sex)
fisher.test(stat_data_sex)

stat_data_stage <- table(clinical_factor$class,clinical_factor$Stage)
fisher.test(stat_data_stage)

stat_data_side <- table(clinical_factor$class,clinical_factor$sidedness)
fisher.test(stat_data_side)



hist(clinical_factor$Age[clinical_factor$class=="P"])
hist(clinical_factor$Age[clinical_factor$class=="Pm"])

tapply(clinical_factor$Age,clinical_factor$class, summary)
t.test(Age ~ class, clinical_factor)
```


### Survival analysis

#### Stage

```{r}
data <- merge(datasurv1, clinical, by="row.names")

fit <- survfit(Surv(time, Status) ~ Stage, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ Stage, data = data)
surv.stage

```


#### Class - PM vs. P

```{r}

fit <- survfit(Surv(time, Status) ~ class, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ class, data = data)
surv.stage

```


#### Sidedness

```{r}
newdata <- data[-which(data$sidedness == "rectum"),]
fit <- survfit(Surv(time, Status) ~ sidedness, data = newdata)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = newdata, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ sidedness, data = newdata)
surv.stage

```


### DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                         rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_d2.xlsx")

top100_deg <- rownames(genes_deg[1:100,])
# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)
top100_high <- rownames(high[1:100,])

#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)
top100_low <- rownames(low[1:100,])
```

### Classification

- In this work we tested 3 different types of classification: 1) Classification without regularization based on DEGs; 2) Classification with regularization (EN and iTwiner); 3) Classification without regularization based on genes selected by regularized logistic regression;

```{r}
xdata.raw <- xdataT

# keep features with standard deviation > 0
xdata <- xdata.raw[,sapply(seq(ncol(xdata.raw)), function(ix) {sd(xdata.raw[,ix])}) != 0]

ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

# ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```


#### 1) Classification without regularization based on DEGs

Five classifiers were used: Decision trees, linear and radial support vector machines, logistic regression and random forest

- Lets pick up the 50 deferentially expressed genes with lowest pvalue found above

```{r}
xdata <- xdataT[,top100_deg[1:50]]

nomesgenes <- colnames(xdata)
colnames(xdata) <- paste0("Var", 1:50)
colnames(ydata) <- c("class","row")
xdata$type <- as.factor(ydata$class)

#xdata <- xdata[colMeans(xdata == 0) <= 0.6] #delete genes that have null values in at least 60% of the samples

```

- Test the different classifiers 100 times to obtain median values for the measures of model performance such as accuracy, misclassification, sensitivity and specificity, among others

```{r, echo=FALSE,warning=FALSE,message=FALSE}

times_boot <- 100

acc <- matrix(0,5,times_boot)
kappa<- matrix(0,5,times_boot)
sensitivity<- matrix(0,5,times_boot)
specificity <- matrix(0,5,times_boot)
miscl <- matrix(0,5,times_boot)
fpos <- matrix(0,5,times_boot)
fneg <- matrix(0,5,times_boot)
auc <- matrix(0,5,times_boot)

acc_train <- matrix(0,5,times_boot)
kappa_train<- matrix(0,5,times_boot)
sensitivity_train<- matrix(0,5,times_boot)
specificity_train <- matrix(0,5,times_boot)
miscl_train <- matrix(0,5,times_boot)
fpos_train <- matrix(0,5,times_boot)
fneg_train <- matrix(0,5,times_boot)
auc_train <- matrix(0,5,times_boot)

ids_fn_tree1 <- vector("list")
ids_fn_svmL1 <- vector("list")
ids_fn_svmR1 <- vector("list")
ids_fn_logist1 <- vector("list")
ids_fn_rf1 <- vector("list")

ids_fp_tree1 <- vector("list")
ids_fp_svmL1 <- vector("list")
ids_fp_svmR1 <- vector("list")
ids_fp_logist1 <- vector("list")
ids_fp_rf1 <- vector("list")


run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)


  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  training <- xdata[ixs$train,]
  testing <- xdata[ixs$test,]


# Classification 

## Decision tree
### Fit the model on the training set

control <- rpart.control(minsplit = 4)

model2 <- rpart(type~., data = training, method = 'class', control = control)

  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[1,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[1,i] <- t[1,2]+t[2,1]
  fneg_train[1,i] <- t[2,1]
  ###


  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[1,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[1,i] <- length(listafp)
  fneg[1,i] <- length(listafn)
  ids_fn_tree1[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1[[i]] <- rownames(testing[listafp,])


  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[1,i] <- result[["overall"]][["Accuracy"]]
  kappa[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[1,i] <- result[["byClass"]][["Specificity"]]
  miscl[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[2,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[2,i] <- t[1,2]+t[2,1]
  fneg_train[2,i] <- t[2,1]
  
  
  # Test
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[2,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[2,i] <- length(listafp)
  fneg[2,i] <- length(listafn)
  ids_fn_svmL1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[2,i] <- result[["overall"]][["Accuracy"]]
  kappa[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[2,i] <- result[["byClass"]][["Specificity"]]
  miscl[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[3,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[3,i] <- t[1,2]+t[2,1]
  fneg_train[3,i] <- t[2,1]
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[3,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    }  else {
      listafn <- c(listafn, a)
    }
  }

  fpos[3,i] <- length(listafp)
  fneg[3,i] <- length(listafn)
  ids_fn_svmR1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[3,i] <- result[["overall"]][["Accuracy"]]
  kappa[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[3,i] <- result[["byClass"]][["Specificity"]]
  miscl[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


logist <- train(type ~., data = training, method = "LogitBoost",
                trControl=trainControl("cv", number = 10),
                tuneLength = 10)

  # Train
  pred <- predict(logist, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[4,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[4,i] <- t[1,2]+t[2,1]
  fneg_train[4,i] <- t[2,1]
  
  #Test
  
  pred <- predict(logist,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[4,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[4,i] <- length(listafp)
  fneg[4,i] <- length(listafn)
  ids_fn_logist1[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[4,i] <- result[["overall"]][["Accuracy"]]
  kappa[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[4,i] <- result[["byClass"]][["Specificity"]]
  miscl[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # Train
  pred <- predict(model.rf, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[5,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[5,i] <- t[1,2]+t[2,1]
  fneg_train[5,i] <- t[2,1]
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[5,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[5,i] <- length(listafp)
  fneg[5,i] <- length(listafn)
  ids_fn_rf1[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)


  acc[5,i] <- result[["overall"]][["Accuracy"]]
  kappa[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[5,i] <- result[["byClass"]][["Specificity"]]
  miscl[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing,a)
}

```



##### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_train[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_train[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_train[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_train[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_train[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_train[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_train[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_train[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_train[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_train[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_train[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_train[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_train[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_train[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_train[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_train[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_train[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_train[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_train[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_train[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_train[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_train[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_train[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_train[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_train[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_train[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_train[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_train[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_train[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_train[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



##### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```










#### 2) Classification with regularization (EN and iTwiner)

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID
# 
# # ydata.raw$class <- c(rep(0,28),rep(1,34))
#  
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw)
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 1000

nvar_selected_1 <- matrix(0,2,times_boot)

var_selected_en1 <- vector("list")
var_selected_iTwiner1 <- vector("list")

acc_cox_tr <- matrix(0,2,times_boot)
acc_cox_tes <- matrix(0,2,times_boot)
kappa_cox_tr <- matrix(0,2,times_boot)
kappa_cox_tes <- matrix(0,2,times_boot)
sensitivity_cox_tr <- matrix(0,2,times_boot)
sensitivity_cox_tes <- matrix(0,2,times_boot)
specificity_cox_tr <- matrix(0,2,times_boot)
specificity_cox_tes <- matrix(0,2,times_boot)
miscl_cox_tr <- matrix(0,2,times_boot)
miscl_cox_tes <- matrix(0,2,times_boot)
auc_cox_tr <- matrix(0,2,times_boot)
auc_cox_tes <- matrix(0,2,times_boot)


fpos_reg_tr <- matrix(0,2,times_boot)
fpos_reg_ts <- matrix(0,2,times_boot)
fneg_reg_tr <- matrix(0,2,times_boot)
fneg_reg_ts <- matrix(0,2,times_boot)

ids_fn_en <- vector("list")
ids_fn_iTwiner <- vector("list")


ids_fp_en <- vector("list")
ids_fp_iTwiner <- vector("list")

run = 1000

i=1
l1=0
while(l1 < 100){
  
  print(l1)
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  # Classification by sparse logistic regression
  
  ## with the elastic net (EN) penalty
  
  fit_EN1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.2,
                       #foldid=my_foldid,
                       type.measure="mse")
  
  var_selected <- which(fit_EN1$glmnet.fit$beta[,which(fit_EN1$cvm == min(fit_EN1$cvm))] != 0)
  
  nvar_selected_1[1,i] <- length(var_selected)
  
  
  var_selected_en1[[i]] <- names(var_selected)
  
  
  
  if (length(var_selected) > 1){
    
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("en train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[1,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[1,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[1,i] <- t[2,1]
        
        rm(var_selected,resp_train,t,result,a)
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("en pred ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[1,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[1,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }

    fpos_reg_ts[1,i] <- length(listafp)
    fneg_reg_ts[1,i] <- length(listafn)
    ids_fn_en[[i]] <- rownames(xtest[listafn,])
    ids_fp_en[[i]] <- rownames(xtest[listafp,])
    
    
    print("EN")} else{
      print("EN não selecionou variaveis")
    }
  
  rm(pred,t,result)
  
  
  i=i+1
  
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  
  l1 <- length(which(acc_cox_tr[1,]!=0))
  
}
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
i=1
l2=0
while(l2 < 100){
  
  print(i)
  print(l2)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  ## with network information - iTwiner
  
  fit_tco1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.05 ,
                        #foldid=my_foldid,
                        penalty.factor = pen_weight2,
                        type.measure="mse")
  
  var_selected <- which(fit_tco1$glmnet.fit$beta[,which(fit_tco1$cvm == min(fit_tco1$cvm))] != 0)
  
  nvar_selected_1[2,i] <- length(var_selected)
  
  
  var_selected_iTwiner1[[i]] <- names(var_selected)
  
  if (length(var_selected) > 1){
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("iTwiner train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[2,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[2,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[2,i] <- t[2,1]
        rm(var_selected,resp_train,t,result,a)
        
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("iTwiner test ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[2,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[2,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }
    
    fpos_reg_ts[2,i] <- length(listafp)
    fneg_reg_ts[2,i] <- length(listafn)
    ids_fn_iTwiner[[i]] <- rownames(xtest[listafn,])
    ids_fp_iTwiner[[i]] <- rownames(xtest[listafp,])
    
    
    
    print("iTwiner")
    
  } else{
    print("iTwiner não correu")
  }
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  l2 <- length(which(acc_cox_tr[2,]!=0))
  i=i+1
}

```

##### Measures of model performance

```{r}
runs_en_tr <- which(acc_cox_tr[1,]!=0)
runs_itw_tr <- which(acc_cox_tr[2,]!=0)

runs_en_ts <- which(acc_cox_tes[1,]!=0)
runs_itw_ts <- which(acc_cox_tes[2,]!=0)
```

- number variables selected

```{r}
# median number of variables selected
nvar_en <- nvar_selected_1[1,]
nvar_en <- nvar_en[runs_en_tr]
mean(nvar_en)
median(nvar_en)
sd(nvar_en)

nvar_tw <- nvar_selected_1[2,]
nvar_tw <- nvar_tw[runs_itw_tr]
mean(nvar_tw)
median(nvar_tw)
sd(nvar_tw)
```

- Accuracy
```{r}
# EN train
acc_cox_tr_EN <- acc_cox_tr[1,]
acc_cox_tr_EN <- acc_cox_tr_EN[runs_en_tr]
#hist(acc_cox_tr_EN)
mean(acc_cox_tr_EN)  
median(acc_cox_tr_EN)
sd(acc_cox_tr_EN)

# EN test
acc_cox_tes_EN <- acc_cox_tes[1,]
acc_cox_tes_EN <- acc_cox_tes_EN[runs_en_ts]
#hist(acc_cox_tes_EN)
mean(acc_cox_tes_EN)
median(acc_cox_tes_EN)
sd(acc_cox_tes_EN)

#iTwiner train
acc_cox_tr_iTwiner <- acc_cox_tr[2,]
acc_cox_tr_iTwiner <- acc_cox_tr_iTwiner[runs_itw_tr]
#hist(acc_cox_tr_iTwiner)
mean(acc_cox_tr_iTwiner)
median(acc_cox_tr_iTwiner)
sd(acc_cox_tr_iTwiner)

#iTwiner test
acc_cox_tes_iTwiner <- acc_cox_tes[2,]
acc_cox_tes_iTwiner <- acc_cox_tes_iTwiner[runs_itw_ts]
#hist(acc_cox_tes_iTwiner)
mean(acc_cox_tes_iTwiner)
median(acc_cox_tes_iTwiner)
sd(acc_cox_tes_iTwiner)
```
- miscl

```{r}
# EN train
miscl_cox_tr_EN <- miscl_cox_tr[1,]
miscl_cox_tr_EN <- miscl_cox_tr_EN[runs_en_tr]
mean(miscl_cox_tr_EN)  
median(miscl_cox_tr_EN)
sd(miscl_cox_tr_EN)

# EN test
miscl_cox_tes_EN <- miscl_cox_tes[1,]
miscl_cox_tes_EN <- miscl_cox_tes_EN[runs_en_ts]
mean(miscl_cox_tes_EN)
median(miscl_cox_tes_EN)
sd(miscl_cox_tes_EN)

#iTwiner train
miscl_cox_tr_iTwiner <- miscl_cox_tr[2,]
miscl_cox_tr_iTwiner <- miscl_cox_tr_iTwiner[runs_itw_tr]
mean(miscl_cox_tr_iTwiner)
median(miscl_cox_tr_iTwiner)
sd(miscl_cox_tr_iTwiner)

#iTwiner test
miscl_cox_tes_iTwiner <- miscl_cox_tes[2,]
miscl_cox_tes_iTwiner <- miscl_cox_tes_iTwiner[runs_itw_ts]
mean(miscl_cox_tes_iTwiner)
median(miscl_cox_tes_iTwiner)
sd(miscl_cox_tes_iTwiner)
```

- False Neg

```{r}
#EN
fneg_reg_en_train <- fneg_reg_tr[1,runs_en_tr]
mean(fneg_reg_en_train)
median(fneg_reg_en_train)
sd(fneg_reg_en_train)

fneg_reg_en_test <- fneg_reg_ts[1,runs_en_ts]
mean(fneg_reg_en_test)
median(fneg_reg_en_test)
sd(fneg_reg_en_test)

#iTwiner
fneg_reg_iTwiner_train <- fneg_reg_tr[2,runs_itw_tr]
mean(fneg_reg_iTwiner_train)
median(fneg_reg_iTwiner_train)
sd(fneg_reg_iTwiner_train)

fneg_reg_iTwiner_test <- fneg_reg_ts[2,runs_itw_ts]
mean(fneg_reg_iTwiner_test)
median(fneg_reg_iTwiner_test)
sd(fneg_reg_iTwiner_test)
```

- sensitivity

```{r}
# EN train
sensitivity_cox_tr_EN <- sensitivity_cox_tr[1,]
sensitivity_cox_tr_EN <- sensitivity_cox_tr_EN[runs_en_tr]
mean(sensitivity_cox_tr_EN)  
median(sensitivity_cox_tr_EN)
sd(sensitivity_cox_tr_EN)

# EN test
sensitivity_cox_tes_EN <- sensitivity_cox_tes[1,]
sensitivity_cox_tes_EN <- sensitivity_cox_tes_EN[runs_en_ts]
mean(sensitivity_cox_tes_EN)
median(sensitivity_cox_tes_EN)
sd(sensitivity_cox_tes_EN)

#iTwiner train
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr[2,]
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr_iTwiner[runs_itw_tr]
mean(sensitivity_cox_tr_iTwiner)
median(sensitivity_cox_tr_iTwiner)
sd(sensitivity_cox_tr_iTwiner)

#iTwiner test
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes[2,]
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes_iTwiner[runs_itw_ts]
mean(sensitivity_cox_tes_iTwiner)
median(sensitivity_cox_tes_iTwiner)
sd(sensitivity_cox_tes_iTwiner)
```

- specificity

```{r}
# EN train
specificity_cox_tr_EN <- specificity_cox_tr[1,]
specificity_cox_tr_EN <- specificity_cox_tr_EN[runs_en_tr]
mean(specificity_cox_tr_EN)  
median(specificity_cox_tr_EN)
sd(specificity_cox_tr_EN)

# EN test
specificity_cox_tes_EN <- specificity_cox_tes[1,]
specificity_cox_tes_EN <- specificity_cox_tes_EN[runs_en_ts]
mean(specificity_cox_tes_EN)
median(specificity_cox_tes_EN)
sd(specificity_cox_tes_EN)

#iTwiner train
specificity_cox_tr_iTwiner <- specificity_cox_tr[2,]
specificity_cox_tr_iTwiner <- specificity_cox_tr_iTwiner[runs_itw_tr]
mean(specificity_cox_tr_iTwiner)
median(specificity_cox_tr_iTwiner)
sd(specificity_cox_tr_iTwiner)

#iTwiner test
specificity_cox_tes_iTwiner <- specificity_cox_tes[2,]
specificity_cox_tes_iTwiner <- specificity_cox_tes_iTwiner[runs_itw_ts]
mean(specificity_cox_tes_iTwiner)
median(specificity_cox_tes_iTwiner)
sd(specificity_cox_tes_iTwiner)
```


- auc

```{r}
# EN train
auc_cox_tr_EN <- auc_cox_tr[1,]
auc_cox_tr_EN <- auc_cox_tr_EN[runs_en_tr]
mean(auc_cox_tr_EN)  
median(auc_cox_tr_EN)
sd(auc_cox_tr_EN)

# EN test
auc_cox_tes_EN <- auc_cox_tes[1,]
auc_cox_tes_EN <- auc_cox_tes_EN[runs_en_ts]
mean(auc_cox_tes_EN)
median(auc_cox_tes_EN)
sd(auc_cox_tes_EN)

#iTwiner train
auc_cox_tr_iTwiner <- auc_cox_tr[2,]
auc_cox_tr_iTwiner <- auc_cox_tr_iTwiner[runs_itw_tr]
mean(auc_cox_tr_iTwiner)
median(auc_cox_tr_iTwiner)
sd(auc_cox_tr_iTwiner)

#iTwiner test
auc_cox_tes_iTwiner <- auc_cox_tes[2,]
auc_cox_tes_iTwiner <- auc_cox_tes_iTwiner[runs_itw_ts]
mean(auc_cox_tes_iTwiner)
median(auc_cox_tes_iTwiner)
sd(auc_cox_tes_iTwiner)
```





- Names of genes selected

Variables always selected
```{r}
var_selected_alw_select_en <- var_selected_en1[runs_en_ts]
var_selected_alw_select_en1 <-  Reduce(intersect,var_selected_alw_select_en)
print(paste("variables always selected by EN = ",length(var_selected_alw_select_en1)))

var_selected_alw_select_iTwiner <- var_selected_iTwiner1[runs_itw_ts]
var_selected_alw_select_iTwiner1 <-  Reduce(intersect,var_selected_alw_select_iTwiner)
print(paste("variables always selected by iTwiner = ",length(var_selected_alw_select_iTwiner1)))
```

Variables selected in 50 bootstrap samples
```{r}
l = length(var_selected_alw_select_en)
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <-  subset(var_selected_50_select_en, Freq > 0.50*l)
print(paste("variables selected 50% by EN = ",length(var_selected_50_select_en$Var1)))
var_selected_50_select_en$Var1
# 
l = length(var_selected_alw_select_iTwiner)
var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <-  subset(var_selected_50_select_iTwiner, Freq > 0.50*l)
print(paste("variables selected 50% by iTwiner = ",length(var_selected_50_select_iTwiner$Var1)))
var_selected_50_select_iTwiner$Var1
```

- Select the 50 most frequent variables 

```{r}
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <- var_selected_50_select_en[order(var_selected_50_select_en$Freq, decreasing = T),]
hist(var_selected_50_select_en$Freq)
top100_en <- var_selected_50_select_en[1:100,]
top100_en <- top100_en$Var1
top50_en <- top100_en[1:50]
top100_en <- as.data.frame(top100_en)
write_xlsx(top100_en,"List_top100_en_d2.xlsx")

var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <- var_selected_50_select_iTwiner[order(var_selected_50_select_iTwiner$Freq, decreasing = T),]
hist(var_selected_50_select_iTwiner$Freq)
top100_itw <- var_selected_50_select_iTwiner[1:100,]
top100_itw <- top100_itw$Var1
top50_itw <- top100_itw[1:50]
top100_itw <- as.data.frame(top100_itw)
write_xlsx(top100_itw,"List_top100_itw_d2.xlsx")
```

variables in common between EN and iTwiner

```{r}
common_var_selected_50_en_iTwiner <- var_selected_50_select_iTwiner$Var1[which(var_selected_50_select_iTwiner$Var1 %in% var_selected_50_select_en$Var1)]
length(common_var_selected_50_en_iTwiner)
common_var_selected_50_en_iTwiner
```

- Variables selected by EN and iTwiner that are DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]

nomesgenes <- c(as.vector(top50_en),as.vector(top50_itw))
xdata <- xdata[,nomesgenes]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                 rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                               rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_enitw_d2.xlsx")

# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)


#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)

```




#### 3) Classification based on genes selected by regularized logistic regression

##### EN + Classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_en)
xdata_en <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_en)
colnames(xdata_en) <- paste0("Var", 1:50)
xdata_en$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_enplus <- matrix(0,5,times_boot)
kappa_enplus<- matrix(0,5,times_boot)
sensitivity_enplus<- matrix(0,5,times_boot)
specificity_enplus <- matrix(0,5,times_boot)
miscl_enplus <- matrix(0,5,times_boot)
fpos_enplus <- matrix(0,5,times_boot)
fneg_enplus <- matrix(0,5,times_boot)
auc_enplus <- matrix(0,5,times_boot)

acc_enplus_train <- matrix(0,5,times_boot)
kappa_enplus_train<- matrix(0,5,times_boot)
sensitivity_enplus_train<- matrix(0,5,times_boot)
specificity_enplus_train <- matrix(0,5,times_boot)
miscl_enplus_train <- matrix(0,5,times_boot)
fpos_enplus_train <- matrix(0,5,times_boot)
fneg_enplus_train <- matrix(0,5,times_boot)
auc_enplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_enplus <- vector("list")
ids_fn_svmL1_enplus <- vector("list")
ids_fn_svmR1_enplus <- vector("list")
ids_fn_logist1_enplus <- vector("list")
ids_fn_rf1_enplus <- vector("list")

ids_fp_tree1_enplus <- vector("list")
ids_fp_svmL1_enplus <- vector("list")
ids_fp_svmR1_enplus <- vector("list")
ids_fp_logist1_enplus <- vector("list")
ids_fp_rf1_enplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_en[ixs$train,]
  testing <- xdata_en[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[1,i] <- length(listafp)
  fneg_enplus[1,i] <- length(listafn)
  ids_fn_tree1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <-  predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[2,i] <- length(listafp)
  fneg_enplus[2,i] <- length(listafn)
  ids_fn_svmL1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[3,i] <- length(listafp)
  fneg_enplus[3,i] <- length(listafn)
  ids_fn_svmR1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[4,i] <- length(listafp)
  fneg_enplus[4,i] <- length(listafn)
  ids_fn_logist1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[5,i] <- length(listafp)
  fneg_enplus[5,i] <- length(listafn)
  ids_fn_rf1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_enplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}

```


###### Measures of model performance train


- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity
```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg
```{r}
# fneg
fneg_trees <- fneg_enplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_enplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

##### iTwiner + classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_itw)
xdata_iTwiner <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_iTwiner)
colnames(xdata_iTwiner) <- paste0("Var", 1:50)
xdata_iTwiner$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_tcoxplus <- matrix(0,5,times_boot)
kappa_tcoxplus<- matrix(0,5,times_boot)
sensitivity_tcoxplus<- matrix(0,5,times_boot)
specificity_tcoxplus <- matrix(0,5,times_boot)
miscl_tcoxplus <- matrix(0,5,times_boot)
fpos_tcoxplus <- matrix(0,5,times_boot)
fneg_tcoxplus <- matrix(0,5,times_boot)
auc_tcoxplus <- matrix(0,5,times_boot)

acc_tcoxplus_train <- matrix(0,5,times_boot)
kappa_tcoxplus_train<- matrix(0,5,times_boot)
sensitivity_tcoxplus_train<- matrix(0,5,times_boot)
specificity_tcoxplus_train <- matrix(0,5,times_boot)
miscl_tcoxplus_train <- matrix(0,5,times_boot)
fpos_tcoxplus_train <- matrix(0,5,times_boot)
fneg_tcoxplus_train <- matrix(0,5,times_boot)
auc_tcoxplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_tcoxplus <- vector("list")
ids_fn_svmL1_tcoxplus <- vector("list")
ids_fn_svmR1_tcoxplus <- vector("list")
ids_fn_logist1_tcoxplus <- vector("list")
ids_fn_rf1_tcoxplus <- vector("list")

ids_fp_tree1_tcoxplus <- vector("list")
ids_fp_svmL1_tcoxplus <- vector("list")
ids_fp_svmR1_tcoxplus <- vector("list")
ids_fp_logist1_tcoxplus <- vector("list")
ids_fp_rf1_tcoxplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_iTwiner[ixs$train,]
  testing <- xdata_iTwiner[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[1,i] <- length(listafp)
  fneg_tcoxplus[1,i] <- length(listafn)
  ids_fn_tree1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[2,i] <- length(listafp)
  fneg_tcoxplus[2,i] <- length(listafn)
  ids_fn_svmL1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[3,i] <- length(listafp)
  fneg_tcoxplus[3,i] <- length(listafn)
  ids_fn_svmR1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[4,i] <- length(listafp)
  fneg_tcoxplus[4,i] <- length(listafn)
  ids_fn_logist1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[5,i] <- length(listafp)
  fneg_tcoxplus[5,i] <- length(listafn)
  ids_fn_rf1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_tcoxplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}
```


###### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc
```{r}
# auc
auc_trees <- auc_tcoxplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_tcoxplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_tcoxplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```


###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_tcoxplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification
```{r}
# miscl
miscl_trees <- miscl_tcoxplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity
```{r}
# specificity
specificity_trees <- specificity_tcoxplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

```{r}
# save results

#save.image("~/results2_2010_final.RData")
```


### Data final 

```{r}
dt2 <- acc[1,]
dt_en2 <- acc_enplus[1,]
dt_iTwiner2 <- acc_tcoxplus[1,]
#dt_hub <- acc_hubplus[1,]

acc_dt2 <- as.data.frame(c(dt2,dt_en2, dt_iTwiner2
                           #,dt_hub
))
colnames(acc_dt2) <- "acc"
#acc_dt$group <- "HUB + DT"
#acc_dt$group[1:100] <- "DT"
acc_dt2$group <- "DT"
acc_dt2$group[101:200] <- "EN + DT"
acc_dt2$group[201:300] <- "iTwiner + DT"
acc_dt2<- acc_dt2 %>% mutate_if(is.character,factor)
# acc_dt$group <- ordered(acc_dt$group, levels = c("DT", "EN + DT","iTwiner + DT", "HUB + DT"))
acc_dt2$group <- ordered(acc_dt2$group, levels = c("DT", "EN + DT","iTwiner + DT"))

acc_dt2$dataset <- "DATASET2"



svmL2 <- acc[2,]
svmL_en2 <- acc_enplus[2,]
svmL_iTwiner2 <- acc_tcoxplus[2,]

acc_svmL2 <- as.data.frame(c(svmL2,svmL_en2, svmL_iTwiner2
                             #,svmL_hub
))
colnames(acc_svmL2) <- "acc"
acc_svmL2$group <- "svmL"
acc_svmL2$group[101:200] <- "EN + svmL"
acc_svmL2$group[201:300] <- "iTwiner + svmL"
acc_svmL2<- acc_svmL2 %>% mutate_if(is.character,factor)
acc_svmL2$group <- ordered(acc_svmL2$group, levels = c("svmL", "EN + svmL","iTwiner + svmL"))

acc_svmL2$dataset <- "DATASET2"




svmR2 <- acc[3,]
svmR_en2 <- acc_enplus[3,]
svmR_iTwiner2 <- acc_tcoxplus[3,]

acc_svmR2 <- as.data.frame(c(svmR2,svmR_en2, svmR_iTwiner2
                             #,svmR_hub
))
colnames(acc_svmR2) <- "acc"
acc_svmR2$group <- "svmR"
acc_svmR2$group[101:200] <- "EN + svmR"
acc_svmR2$group[201:300] <- "iTwiner + svmR"
acc_svmR2<- acc_svmR2 %>% mutate_if(is.character,factor)
acc_svmR2$group <- ordered(acc_svmR2$group, levels = c("svmR", "EN + svmR","iTwiner + svmR"))

acc_svmR2$dataset <- "DATASET2"






logist2 <- acc[4,]
logist_en2 <- acc_enplus[4,]
logist_iTwiner2 <- acc_tcoxplus[4,]

acc_logist2 <- as.data.frame(c(logist2,logist_en2, logist_iTwiner2
                               #,logist_hub
))
colnames(acc_logist2) <- "acc"
acc_logist2$group <- "logist"
acc_logist2$group[101:200] <- "EN + logist"
acc_logist2$group[201:300] <- "iTwiner + logist"
acc_logist2<- acc_logist2 %>% mutate_if(is.character,factor)
acc_logist2$group <- ordered(acc_logist2$group, levels = c("logist", "EN + logist","iTwiner + logist"))

acc_logist2$dataset <- "DATASET2"






rf2 <- acc[5,]
rf_en2 <- acc_enplus[5,]
rf_iTwiner2 <- acc_tcoxplus[5,]

acc_rf2 <- as.data.frame(c(rf2,rf_en2, rf_iTwiner2
                           #,rf_hub
))
colnames(acc_rf2) <- "acc"
acc_rf2$group <- "rf"
acc_rf2$group[101:200] <- "EN + rf"
acc_rf2$group[201:300] <- "iTwiner + rf"
acc_rf2<- acc_rf2 %>% mutate_if(is.character,factor)
acc_rf2$group <- ordered(acc_rf2$group, levels = c("rf", "EN + rf","iTwiner + rf"))

acc_rf2$dataset <- "DATASET2"





```





## DATASET 3

### DATA

```{r}
load("~/CRC_LCosta/results/results3_2010_final.RData")
DATASET1_bal <- df3
DATASET1 <- DATASET3_bal
clinic1 <- clinic3_bal
datasurv1 <- datasurv3
clinic1_bal <- clinic3_bal
```

- Split dataset in two groups for classification: 
  -- P -> non-metastatic (CLASS = 1)
  -- PM -> metastatic (CLASS = 0)

```{r, warning=FALSE,message=FALSE}
# primM <- DATASET1 %>%
#   filter(str_detect(class, "m"))
# rownames(primM) <- primM$ID
# primN <- DATASET1 %>%
#   filter(!str_detect(class, "Pm"))
# rownames(primN) <- primN$ID
# 
# clinic_prim <- DATASET1
# 
# rnaprimM <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primM),]
# 
# rnaprimN <- rnaseq1[rownames(rnaseq1) %in% 
#                          rownames(primN),]
# 
# rnaprim <- rbind(rnaprimM,rnaprimN)
```

- removing variables with sd=0

```{r, warning=FALSE,message=FALSE}
# xmet <- rnaprimM [,sapply(seq(ncol(rnaprimM)), function(ix) {sd(rnaprimM[,ix])}) != 0] 
# xnon <- rnaprimN[,sapply(seq(ncol(rnaprimN)), function(ix) {sd(rnaprimN[,ix])}) != 0] 
# 
# xmet_less <- xmet[,which(colnames(xmet) %in% colnames(xnon))]
# xnon_less <- xnon[,which(colnames(xnon) %in% colnames(xmet))]
# 
# # normalizing data
# xmet_norm <- scale(log2(xmet_less+1)) 
# xnon_norm <- scale(log2(xnon_less+1)) 
# 
# xdataT <- rbind(xmet_less,xnon_less)
# xdataT <- xdataT[ order(row.names(xdataT)), ]
# 
# 
# rm(xmet,xmet_less,xnon,xnon_less,rnaprimM,rnaprimN)
```

- weight vector that penalizes genes with greater distances between Pm and P correlation matrices - TWINER

```{r, warning=FALSE,message=FALSE}
# #xmet_cor <- Matrix(cor(xmet_norm), sparse = TRUE)
# xmet_cor <- cor(xmet_norm)
# #xmet_cor <- as.data.frame(xmet_cor)
# xnon_cor <- cor(xnon_norm)
# #xnon_cor <- as.data.frame(xnon_cor)
# 
# # angular distance
# ang_weight <- vector()
# for (i in 1:dim(xmet_cor)[2]){ 
# ang_weight[i] <- acos(cosine(xmet_cor[,i],xnon_cor[,i]))/pi
# }
# 
# ## normalized weights
# 
# weights <- ang_weight / max(ang_weight)
# hist(weights,main="w")
# 
# 
# pen_weight3 <- 1 / weights
# hist(pen_weight3, main="1 / w")
# 
# rm(xmet_cor,xnon_cor)
```

### Exploratory analysis

- All dataset x

```{r}
clinical <- as.data.frame(clinic1_bal)


basic_eda <- function(clinical)
{
  glimpse(clinical)
  #df_Status(clinical)
  freq(clinical) 
  profiling_num(clinical)
  plot_num(clinical)
  describe(clinic1)
}
basic_eda(clinical)

a <- na.omit(clinical$Age)
mean(a)
``` 

- Only patients that do not metastasize

```{r}
clinical_p <- clinic1_bal %>%
  filter(!str_detect(class, "Pm"))


basic_eda <- function(clinical_p)
{
  glimpse(clinical_p)
  #df_Status(clinical_p)
  freq(clinical_p) 
  profiling_num(clinical_p)
  plot_num(clinical_p)
  describe(clinical_p)
}
basic_eda(clinical_p)

a <- na.omit(clinical_p$Age)
mean(a)
```

- Only patients that do metastasize

```{r}
clinical_Pm <- clinic1_bal%>%
  filter(str_detect(class, "Pm"))


basic_eda <- function(clinical_Pm)
{
  glimpse(clinical_Pm)
  #df_Status(clinical_Pm)
  freq(clinical_Pm) 
  profiling_num(clinical_Pm)
  plot_num(clinical_Pm)
  describe(clinical_Pm)
}
basic_eda(clinical_Pm)

a <- na.omit(clinical_Pm$Age)
mean(a)

```

- Statistic differences between patients groups regarding several variables

```{r}
clinical_factor <- clinic1_bal
clinical_factor <- clinical_factor %>%
  mutate_if(sapply(clinical_factor, is.character), as.factor)
#clinical_factor <- na.omit(clinical_factor)

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  organ), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Sex), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

clinical_factor1 <- clinical_factor %>%
  filter(!str_detect(sidedness, "rectum"))

ggplot(data = clinical_factor1) + 
  geom_bar(mapping = aes(x = class, fill =  sidedness), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4"))

ggplot(data = clinical_factor) + 
  geom_bar(mapping = aes(x = class, fill =  Stage), position = "fill") + scale_fill_manual(values=c("#ADD8E6", "#4682B4", "#000080"))


clinical_factor %>%
  ggplot( aes(x=Age, fill=class)) +
    geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) 
    labs(fill="")

```

```{r}
stat_data_organ <- table(clinical_factor$class,clinical_factor$organ)
#fazer plot(...)
fisher.test(stat_data_organ)

stat_data_sex <- table(clinical_factor$class,clinical_factor$Sex)
fisher.test(stat_data_sex)

stat_data_stage <- table(clinical_factor$class,clinical_factor$Stage)
fisher.test(stat_data_stage)

stat_data_side <- table(clinical_factor$class,clinical_factor$sidedness)
fisher.test(stat_data_side)



hist(clinical_factor$Age[clinical_factor$class=="P"])
hist(clinical_factor$Age[clinical_factor$class=="Pm"])

tapply(clinical_factor$Age,clinical_factor$class, summary)
t.test(Age ~ class, clinical_factor)
```


### Survival analysis

#### Stage

```{r}
data <- merge(datasurv1, clinical, by="row.names")

fit <- survfit(Surv(time, Status) ~ Stage, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ Stage, data = data)
surv.stage

```


#### Class - PM vs. P

```{r}

fit <- survfit(Surv(time, Status) ~ class, data = data)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = data, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ class, data = data)
surv.stage

```


#### Sidedness

```{r}
newdata <- data[-which(data$sidedness == "rectum"),]
fit <- survfit(Surv(time, Status) ~ sidedness, data = newdata)
print(fit)

# Summary of survival curves
summary(fit)
# Access to the sort summary table
summary(fit)$table


ggsurvplot(fit, data = newdata, pval = TRUE)


# the log/rank test
surv.stage <- survdiff(Surv(time,Status) ~ sidedness, data = newdata)
surv.stage

```


### DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                         rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_d3.xlsx")

top100_deg <- rownames(genes_deg[1:100,])
# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)
top100_high <- rownames(high[1:100,])

#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)
top100_low <- rownames(low[1:100,])
```

### Classification

- In this work we tested 3 different types of classification: 1) Classification without regularization based on DEGs; 2) Classification with regularization (EN and iTwiner); 3) Classification without regularization based on genes selected by regularized logistic regression;

```{r}
xdata.raw <- xdataT

# keep features with standard deviation > 0
xdata <- xdata.raw[,sapply(seq(ncol(xdata.raw)), function(ix) {sd(xdata.raw[,ix])}) != 0]

ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

# ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```


#### 1) Classification without regularization based on DEGs

Five classifiers were used: Decision trees, linear and radial support vector machines, logistic regression and random forest

- Lets pick up the 50 deferentially expressed genes with lowest pvalue found above

```{r}
xdata <- xdataT[,top100_deg[1:50]]

nomesgenes <- colnames(xdata)
colnames(xdata) <- paste0("Var", 1:50)
colnames(ydata) <- c("class","row")
xdata$type <- as.factor(ydata$class)

#xdata <- xdata[colMeans(xdata == 0) <= 0.6] #delete genes that have null values in at least 60% of the samples

```

- Test the different classifiers 100 times to obtain median values for the measures of model performance such as accuracy, misclassification, sensitivity and specificity, among others

```{r, echo=FALSE,warning=FALSE,message=FALSE}

times_boot <- 100

acc <- matrix(0,5,times_boot)
kappa<- matrix(0,5,times_boot)
sensitivity<- matrix(0,5,times_boot)
specificity <- matrix(0,5,times_boot)
miscl <- matrix(0,5,times_boot)
fpos <- matrix(0,5,times_boot)
fneg <- matrix(0,5,times_boot)
auc <- matrix(0,5,times_boot)

acc_train <- matrix(0,5,times_boot)
kappa_train<- matrix(0,5,times_boot)
sensitivity_train<- matrix(0,5,times_boot)
specificity_train <- matrix(0,5,times_boot)
miscl_train <- matrix(0,5,times_boot)
fpos_train <- matrix(0,5,times_boot)
fneg_train <- matrix(0,5,times_boot)
auc_train <- matrix(0,5,times_boot)

ids_fn_tree1 <- vector("list")
ids_fn_svmL1 <- vector("list")
ids_fn_svmR1 <- vector("list")
ids_fn_logist1 <- vector("list")
ids_fn_rf1 <- vector("list")

ids_fp_tree1 <- vector("list")
ids_fp_svmL1 <- vector("list")
ids_fp_svmR1 <- vector("list")
ids_fp_logist1 <- vector("list")
ids_fp_rf1 <- vector("list")


run = 1000


for (i in 1:times_boot){

  print(i)
  run = run + 11
  set.seed(run)
  print(run)


  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  training <- xdata[ixs$train,]
  testing <- xdata[ixs$test,]


# Classification 

## Decision tree
### Fit the model on the training set

control <- rpart.control(minsplit = 4)

model2 <- rpart(type~., data = training, method = 'class', control = control)

  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[1,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[1,i] <- t[1,2]+t[2,1]
  fneg_train[1,i] <- t[2,1]
  ###


  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[1,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[1,i] <- length(listafp)
  fneg[1,i] <- length(listafn)
  ids_fn_tree1[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1[[i]] <- rownames(testing[listafp,])


  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[1,i] <- result[["overall"]][["Accuracy"]]
  kappa[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[1,i] <- result[["byClass"]][["Specificity"]]
  miscl[1,i] <- t[1,2]+t[2,1]
  ###



## SVM linear

  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[2,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[2,i] <- t[1,2]+t[2,1]
  fneg_train[2,i] <- t[2,1]
  
  
  # Test
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[2,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[2,i] <- length(listafp)
  fneg[2,i] <- length(listafn)
  ids_fn_svmL1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[2,i] <- result[["overall"]][["Accuracy"]]
  kappa[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[2,i] <- result[["byClass"]][["Specificity"]]
  miscl[2,i] <- t[1,2]+t[2,1]

  ###


## SVM radial

  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)

  
  # Train
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[3,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[3,i] <- t[1,2]+t[2,1]
  fneg_train[3,i] <- t[2,1]
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[3,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    }  else {
      listafn <- c(listafn, a)
    }
  }

  fpos[3,i] <- length(listafp)
  fneg[3,i] <- length(listafn)
  ids_fn_svmR1[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[3,i] <- result[["overall"]][["Accuracy"]]
  kappa[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[3,i] <- result[["byClass"]][["Specificity"]]
  miscl[3,i] <- t[1,2]+t[2,1]
  ###



## Logistic Regression


logist <- train(type ~., data = training, method = "LogitBoost",
                trControl=trainControl("cv", number = 10),
                tuneLength = 10)

  # Train
  pred <- predict(logist, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[4,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[4,i] <- t[1,2]+t[2,1]
  fneg_train[4,i] <- t[2,1]
  
  #Test
  
  pred <- predict(logist,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[4,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[4,i] <- length(listafp)
  fneg[4,i] <- length(listafn)
  ids_fn_logist1[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)

  acc[4,i] <- result[["overall"]][["Accuracy"]]
  kappa[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[4,i] <- result[["byClass"]][["Specificity"]]
  miscl[4,i] <- t[1,2]+t[2,1]

  ###



## Random forest

  model.rf <- train(type ~., data = training, method = "rf",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # Train
  pred <- predict(model.rf, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_train[5,i] <- auc(training$type, a)

  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)

  acc_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_train[5,i] <- t[1,2]+t[2,1]
  fneg_train[5,i] <- t[2,1]
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc[5,i] <- auc(testing$type, a)

  true <- testing$type

  listafp <- c()
  listafn <- c()

  for (a in which(pred!= true)){

    if (pred[a] == 0) {

      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }

  fpos[5,i] <- length(listafp)
  fneg[5,i] <- length(listafn)
  ids_fn_rf1[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1[[i]] <- rownames(testing[listafp,])

  #Calculating accuracy

  t <- table(pred,testing$type)
  result <- confusionMatrix(t)


  acc[5,i] <- result[["overall"]][["Accuracy"]]
  kappa[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity[5,i] <- result[["byClass"]][["Specificity"]]
  miscl[5,i] <- t[1,2]+t[2,1]




  ###




  rm(training,testing,a)
}

```



##### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_train[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_train[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_train[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_train[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_train[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_train[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_train[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_train[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_train[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_train[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_train[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_train[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_train[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_train[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_train[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_train[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_train[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_train[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_train[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_train[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_train[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_train[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_train[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_train[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_train[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_train[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_train[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_train[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_train[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_train[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



##### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc[1,]
hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc[2,]
hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc[3,]
hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc[4,]
hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc[5,]
hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc[1,]
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc[2,]
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc[3,]
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc[4,]
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc[5,]
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl[1,]
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl[2,]
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl[3,]
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl[4,]
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl[5,]
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)


```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity[1,]
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity[2,]
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity[3,]
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity[4,]
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity[5,]
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity[1,]
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity[2,]
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity[3,]
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity[4,]
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity[5,]
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)


```

- False Neg

```{r}
# fneg
fneg_trees <- fneg[1,]
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg[2,]
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg[3,]
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg[4,]
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg[5,]
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```










#### 2) Classification with regularization (EN and iTwiner)

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID
# 
# # ydata.raw$class <- c(rep(0,28),rep(1,34))
#  
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw)
ydata$`clinic1$class` <- as.numeric(ydata$`clinic1$class`)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 1000

nvar_selected_1 <- matrix(0,2,times_boot)

var_selected_en1 <- vector("list")
var_selected_iTwiner1 <- vector("list")

acc_cox_tr <- matrix(0,2,times_boot)
acc_cox_tes <- matrix(0,2,times_boot)
kappa_cox_tr <- matrix(0,2,times_boot)
kappa_cox_tes <- matrix(0,2,times_boot)
sensitivity_cox_tr <- matrix(0,2,times_boot)
sensitivity_cox_tes <- matrix(0,2,times_boot)
specificity_cox_tr <- matrix(0,2,times_boot)
specificity_cox_tes <- matrix(0,2,times_boot)
miscl_cox_tr <- matrix(0,2,times_boot)
miscl_cox_tes <- matrix(0,2,times_boot)
auc_cox_tr <- matrix(0,2,times_boot)
auc_cox_tes <- matrix(0,2,times_boot)


fpos_reg_tr <- matrix(0,2,times_boot)
fpos_reg_ts <- matrix(0,2,times_boot)
fneg_reg_tr <- matrix(0,2,times_boot)
fneg_reg_ts <- matrix(0,2,times_boot)

ids_fn_en <- vector("list")
ids_fn_iTwiner <- vector("list")


ids_fp_en <- vector("list")
ids_fp_iTwiner <- vector("list")

run = 1000

i=1
l1=0
while(l1 < 100){
  
  print(l1)
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  # Classification by sparse logistic regression
  
  ## with the elastic net (EN) penalty
  
  fit_EN1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.2,
                       #foldid=my_foldid,
                       type.measure="mse")
  
  var_selected <- which(fit_EN1$glmnet.fit$beta[,which(fit_EN1$cvm == min(fit_EN1$cvm))] != 0)
  
  nvar_selected_1[1,i] <- length(var_selected)
  
  
  var_selected_en1[[i]] <- names(var_selected)
  
  
  
  if (length(var_selected) > 1){
    
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("en train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[1,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[1,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[1,i] <- t[2,1]
        
        rm(var_selected,resp_train,t,result,a)
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_EN1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("en pred ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[1,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[1,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[1,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[1,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[1,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[1,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }

    fpos_reg_ts[1,i] <- length(listafp)
    fneg_reg_ts[1,i] <- length(listafn)
    ids_fn_en[[i]] <- rownames(xtest[listafn,])
    ids_fp_en[[i]] <- rownames(xtest[listafp,])
    
    
    print("EN")} else{
      print("EN não selecionou variaveis")
    }
  
  rm(pred,t,result)
  
  
  i=i+1
  
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  
  l1 <- length(which(acc_cox_tr[1,]!=0))
  
}
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
i=1
l2=0
while(l2 < 100){
  
  print(i)
  print(l2)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$`clinic1$class`)), which(as.logical(!ydata$`clinic1$class` )), train.perc = 0.7)
  xtrain <- xdata[ixs$train,]
  ytrain <- ydata[ixs$train,1]
  
  xtest <- xdata[ixs$test,]
  ytest <- ydata[ixs$test,1]
  
  print("data")
  
  xtrain <- as.matrix(xtrain)
  xtest <- as.matrix(xtest)
  
  
  ## with network information - iTwiner
  
  fit_tco1 <- cv.glmnet(as.matrix(xtrain), as.factor(ytrain), family="binomial", nfolds=10, alpha=0.05 ,
                        #foldid=my_foldid,
                        penalty.factor = pen_weight3,
                        type.measure="mse")
  
  var_selected <- which(fit_tco1$glmnet.fit$beta[,which(fit_tco1$cvm == min(fit_tco1$cvm))] != 0)
  
  nvar_selected_1[2,i] <- length(var_selected)
  
  
  var_selected_iTwiner1[[i]] <- names(var_selected)
  
  if (length(var_selected) > 1){
    # results
    
    ##train
    resp_train <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtrain, type = 'class'))
    resp_train <- resp_train[,1]
    
    if (length(which(resp_train == 0)) == 0 | length(which(resp_train == 1)) == 0){
      
      print("iTwiner train ups")} else{
        
        a <- as.vector(resp_train)
        a <- as.numeric(a)
        
        auc_cox_tr[2,i] <- auc(ytrain, a)
        
        t <- table(resp_train,ytrain)
        result <- confusionMatrix(t)
        
        acc_cox_tr[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tr[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tr[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tr[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tr[2,i] <- t[1,2]+t[2,1]
        fneg_reg_tr[2,i] <- t[2,1]
        rm(var_selected,resp_train,t,result,a)
        
      }
    
    
    
    ## test
    pred <- as.data.frame(predict(fit_tco1, s = 'lambda.min', newx = xtest, type = 'class'))
    pred <- pred[,1]
    
    if (length(which(pred == 0)) == 0 | length(which(pred == 1)) == 0){
      
      print("iTwiner test ups")} else{
        
        a <- as.vector(pred)
        a <- as.numeric(a)
        
        auc_cox_tes[2,i] <- auc(ytest, a)
        
        t <- table(pred,ytest)
        result <- confusionMatrix(t)
        
        acc_cox_tes[2,i] <- result[["overall"]][["Accuracy"]]
        kappa_cox_tes[2,i] <- result[["overall"]][["Kappa"]]
        sensitivity_cox_tes[2,i] <- result[["byClass"]][["Sensitivity"]]
        specificity_cox_tes[2,i] <- result[["byClass"]][["Specificity"]]
        miscl_cox_tes[2,i] <- t[1,2]+t[2,1]
        
      }
    
    true <- ytest
    
    listafp <- c()
    listafn <- c()
    
    for (a in which(pred!= true)){
      
      if (pred[a] == 0) {
        
        listafp <- c(listafp, a)
      } else {
        listafn <- c(listafn, a)
      }
    }
    
    fpos_reg_ts[2,i] <- length(listafp)
    fneg_reg_ts[2,i] <- length(listafn)
    ids_fn_iTwiner[[i]] <- rownames(xtest[listafn,])
    ids_fp_iTwiner[[i]] <- rownames(xtest[listafp,])
    
    
    
    print("iTwiner")
    
  } else{
    print("iTwiner não correu")
  }
  
  rm(xtrain,xtest,ytrain,ytest,ytest,a)
  l2 <- length(which(acc_cox_tr[2,]!=0))
  i=i+1
}

```

##### Measures of model performance

```{r}
runs_en_tr <- which(acc_cox_tr[1,]!=0)
runs_itw_tr <- which(acc_cox_tr[2,]!=0)

runs_en_ts <- which(acc_cox_tes[1,]!=0)
runs_itw_ts <- which(acc_cox_tes[2,]!=0)
```

- number variables selected

```{r}
# median number of variables selected
nvar_en <- nvar_selected_1[1,]
nvar_en <- nvar_en[runs_en_tr]
mean(nvar_en)
median(nvar_en)
sd(nvar_en)

nvar_tw <- nvar_selected_1[2,]
nvar_tw <- nvar_tw[runs_itw_tr]
mean(nvar_tw)
median(nvar_tw)
sd(nvar_tw)
```

- Accuracy
```{r}
# EN train
acc_cox_tr_EN <- acc_cox_tr[1,]
acc_cox_tr_EN <- acc_cox_tr_EN[runs_en_tr]
#hist(acc_cox_tr_EN)
mean(acc_cox_tr_EN)  
median(acc_cox_tr_EN)
sd(acc_cox_tr_EN)

# EN test
acc_cox_tes_EN <- acc_cox_tes[1,]
acc_cox_tes_EN <- acc_cox_tes_EN[runs_en_ts]
#hist(acc_cox_tes_EN)
mean(acc_cox_tes_EN)
median(acc_cox_tes_EN)
sd(acc_cox_tes_EN)

#iTwiner train
acc_cox_tr_iTwiner <- acc_cox_tr[2,]
acc_cox_tr_iTwiner <- acc_cox_tr_iTwiner[runs_itw_tr]
#hist(acc_cox_tr_iTwiner)
mean(acc_cox_tr_iTwiner)
median(acc_cox_tr_iTwiner)
sd(acc_cox_tr_iTwiner)

#iTwiner test
acc_cox_tes_iTwiner <- acc_cox_tes[2,]
acc_cox_tes_iTwiner <- acc_cox_tes_iTwiner[runs_itw_ts]
#hist(acc_cox_tes_iTwiner)
mean(acc_cox_tes_iTwiner)
median(acc_cox_tes_iTwiner)
sd(acc_cox_tes_iTwiner)
```
- miscl

```{r}
# EN train
miscl_cox_tr_EN <- miscl_cox_tr[1,]
miscl_cox_tr_EN <- miscl_cox_tr_EN[runs_en_tr]
mean(miscl_cox_tr_EN)  
median(miscl_cox_tr_EN)
sd(miscl_cox_tr_EN)

# EN test
miscl_cox_tes_EN <- miscl_cox_tes[1,]
miscl_cox_tes_EN <- miscl_cox_tes_EN[runs_en_ts]
mean(miscl_cox_tes_EN)
median(miscl_cox_tes_EN)
sd(miscl_cox_tes_EN)

#iTwiner train
miscl_cox_tr_iTwiner <- miscl_cox_tr[2,]
miscl_cox_tr_iTwiner <- miscl_cox_tr_iTwiner[runs_itw_tr]
mean(miscl_cox_tr_iTwiner)
median(miscl_cox_tr_iTwiner)
sd(miscl_cox_tr_iTwiner)

#iTwiner test
miscl_cox_tes_iTwiner <- miscl_cox_tes[2,]
miscl_cox_tes_iTwiner <- miscl_cox_tes_iTwiner[runs_itw_ts]
mean(miscl_cox_tes_iTwiner)
median(miscl_cox_tes_iTwiner)
sd(miscl_cox_tes_iTwiner)
```

- False Neg

```{r}
#EN
fneg_reg_en_train <- fneg_reg_tr[1,runs_en_tr]
mean(fneg_reg_en_train)
median(fneg_reg_en_train)
sd(fneg_reg_en_train)

fneg_reg_en_test <- fneg_reg_ts[1,runs_en_ts]
mean(fneg_reg_en_test)
median(fneg_reg_en_test)
sd(fneg_reg_en_test)

#iTwiner
fneg_reg_iTwiner_train <- fneg_reg_tr[2,runs_itw_tr]
mean(fneg_reg_iTwiner_train)
median(fneg_reg_iTwiner_train)
sd(fneg_reg_iTwiner_train)

fneg_reg_iTwiner_test <- fneg_reg_ts[2,runs_itw_ts]
mean(fneg_reg_iTwiner_test)
median(fneg_reg_iTwiner_test)
sd(fneg_reg_iTwiner_test)
```

- sensitivity

```{r}
# EN train
sensitivity_cox_tr_EN <- sensitivity_cox_tr[1,]
sensitivity_cox_tr_EN <- sensitivity_cox_tr_EN[runs_en_tr]
mean(sensitivity_cox_tr_EN)  
median(sensitivity_cox_tr_EN)
sd(sensitivity_cox_tr_EN)

# EN test
sensitivity_cox_tes_EN <- sensitivity_cox_tes[1,]
sensitivity_cox_tes_EN <- sensitivity_cox_tes_EN[runs_en_ts]
mean(sensitivity_cox_tes_EN)
median(sensitivity_cox_tes_EN)
sd(sensitivity_cox_tes_EN)

#iTwiner train
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr[2,]
sensitivity_cox_tr_iTwiner <- sensitivity_cox_tr_iTwiner[runs_itw_tr]
mean(sensitivity_cox_tr_iTwiner)
median(sensitivity_cox_tr_iTwiner)
sd(sensitivity_cox_tr_iTwiner)

#iTwiner test
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes[2,]
sensitivity_cox_tes_iTwiner <- sensitivity_cox_tes_iTwiner[runs_itw_ts]
mean(sensitivity_cox_tes_iTwiner)
median(sensitivity_cox_tes_iTwiner)
sd(sensitivity_cox_tes_iTwiner)
```

- specificity

```{r}
# EN train
specificity_cox_tr_EN <- specificity_cox_tr[1,]
specificity_cox_tr_EN <- specificity_cox_tr_EN[runs_en_tr]
mean(specificity_cox_tr_EN)  
median(specificity_cox_tr_EN)
sd(specificity_cox_tr_EN)

# EN test
specificity_cox_tes_EN <- specificity_cox_tes[1,]
specificity_cox_tes_EN <- specificity_cox_tes_EN[runs_en_ts]
mean(specificity_cox_tes_EN)
median(specificity_cox_tes_EN)
sd(specificity_cox_tes_EN)

#iTwiner train
specificity_cox_tr_iTwiner <- specificity_cox_tr[2,]
specificity_cox_tr_iTwiner <- specificity_cox_tr_iTwiner[runs_itw_tr]
mean(specificity_cox_tr_iTwiner)
median(specificity_cox_tr_iTwiner)
sd(specificity_cox_tr_iTwiner)

#iTwiner test
specificity_cox_tes_iTwiner <- specificity_cox_tes[2,]
specificity_cox_tes_iTwiner <- specificity_cox_tes_iTwiner[runs_itw_ts]
mean(specificity_cox_tes_iTwiner)
median(specificity_cox_tes_iTwiner)
sd(specificity_cox_tes_iTwiner)
```


- auc

```{r}
# EN train
auc_cox_tr_EN <- auc_cox_tr[1,]
auc_cox_tr_EN <- auc_cox_tr_EN[runs_en_tr]
mean(auc_cox_tr_EN)  
median(auc_cox_tr_EN)
sd(auc_cox_tr_EN)

# EN test
auc_cox_tes_EN <- auc_cox_tes[1,]
auc_cox_tes_EN <- auc_cox_tes_EN[runs_en_ts]
mean(auc_cox_tes_EN)
median(auc_cox_tes_EN)
sd(auc_cox_tes_EN)

#iTwiner train
auc_cox_tr_iTwiner <- auc_cox_tr[2,]
auc_cox_tr_iTwiner <- auc_cox_tr_iTwiner[runs_itw_tr]
mean(auc_cox_tr_iTwiner)
median(auc_cox_tr_iTwiner)
sd(auc_cox_tr_iTwiner)

#iTwiner test
auc_cox_tes_iTwiner <- auc_cox_tes[2,]
auc_cox_tes_iTwiner <- auc_cox_tes_iTwiner[runs_itw_ts]
mean(auc_cox_tes_iTwiner)
median(auc_cox_tes_iTwiner)
sd(auc_cox_tes_iTwiner)
```





- Names of genes selected

Variables always selected
```{r}
var_selected_alw_select_en <- var_selected_en1[runs_en_ts]
var_selected_alw_select_en1 <-  Reduce(intersect,var_selected_alw_select_en)
print(paste("variables always selected by EN = ",length(var_selected_alw_select_en1)))

var_selected_alw_select_iTwiner <- var_selected_iTwiner1[runs_itw_ts]
var_selected_alw_select_iTwiner1 <-  Reduce(intersect,var_selected_alw_select_iTwiner)
print(paste("variables always selected by iTwiner = ",length(var_selected_alw_select_iTwiner1)))
```

Variables selected in 50 bootstrap samples
```{r}
l = length(var_selected_alw_select_en)
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <-  subset(var_selected_50_select_en, Freq > 0.50*l)
print(paste("variables selected 50% by EN = ",length(var_selected_50_select_en$Var1)))
var_selected_50_select_en$Var1
# 
l = length(var_selected_alw_select_iTwiner)
var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <-  subset(var_selected_50_select_iTwiner, Freq > 0.50*l)
print(paste("variables selected 50% by iTwiner = ",length(var_selected_50_select_iTwiner$Var1)))
var_selected_50_select_iTwiner$Var1
```

- Select the 50 most frequent variables 

```{r}
var_selected_50_select_en <- table(unlist(var_selected_alw_select_en))
var_selected_50_select_en <- as.data.frame(var_selected_50_select_en)
var_selected_50_select_en <- var_selected_50_select_en[order(var_selected_50_select_en$Freq, decreasing = T),]
hist(var_selected_50_select_en$Freq)
top100_en <- var_selected_50_select_en[1:100,]
top100_en <- top100_en$Var1
top50_en <- top100_en[1:50]
top100_en <- as.data.frame(top100_en)
write_xlsx(top100_en,"List_top100_en_d3.xlsx")


var_selected_50_select_iTwiner <- table(unlist(var_selected_alw_select_iTwiner))
var_selected_50_select_iTwiner <- as.data.frame(var_selected_50_select_iTwiner)
var_selected_50_select_iTwiner <- var_selected_50_select_iTwiner[order(var_selected_50_select_iTwiner$Freq, decreasing = T),]
hist(var_selected_50_select_iTwiner$Freq)
top100_itw <- var_selected_50_select_iTwiner[1:100,]
top100_itw <- top100_itw$Var1
top50_itw <- top100_itw[1:50]
top100_itw <- as.data.frame(top100_itw)
write_xlsx(top100_itw,"List_top100_itw_d3.xlsx")
```

variables in common between EN and iTwiner

```{r}
common_var_selected_50_en_iTwiner <- var_selected_50_select_iTwiner$Var1[which(var_selected_50_select_iTwiner$Var1 %in% var_selected_50_select_en$Var1)]
length(common_var_selected_50_en_iTwiner)
common_var_selected_50_en_iTwiner
```

- Variables selected by EN and iTwiner that are DEGs

```{r, warning=FALSE,message=FALSE}
xdata <- rnaseq1[ order(row.names(rnaseq1)), ]

nomesgenes <- c(as.vector(top50_en),as.vector(top50_itw))
xdata <- xdata[,nomesgenes]
rownames(DATASET1_bal) <- DATASET1_bal$ID
ydata <- as.data.frame(DATASET1_bal[ order(row.names(DATASET1_bal)), ])
rownames(ydata) <- ydata$ID

xdata <- xdata[rownames(xdata) %in% 
                 rownames(ydata),]
ydata <- as.data.frame(ydata[rownames(ydata) %in% 
                               rownames(xdata),])

# keep features with standard deviation > 0
xdata <- xdata[,sapply(seq(ncol(xdata)), function(ix) {sd(xdata[,ix])}) != 0]
xdata <- t(xdata)

group <- as.factor(ydata$class)
class <- as.data.frame(ydata$class)

```

```{r}
edgeR.DGElist <- DGEList(counts=xdata, group = group)

# remove genes that do not have one count per million in at least 5 samples
keep <- rowSums(cpm(edgeR.DGElist) >= 1) >= 5
edgeR.DGElist <- edgeR.DGElist[keep ,]

# specify the design setup 

design <- model.matrix(~group)

# estimate the dispersion for all read counts across all samples
edgeR.DGElist <- estimateDisp(edgeR.DGElist, design)

# fit the negative binomial model
edger_fit <- glmFit(edgeR.DGElist, design )

# perform the testing for every gene using the neg. binomial model
edger_lrt <- glmLRT(edger_fit)
summary(decideTests(edger_lrt))

# extract results from edger _lrt$ table plus adjusted p- values
DGE.results_edgeR <- topTags(edger_lrt, n = Inf , sort.by = "PValue" , adjust.method = "BH" )

topTags(DGE.results_edgeR) #table with the top10 DEGs

genes_deg <- DGE.results_edgeR$table
genes_deg <- genes_deg[which(genes_deg$FDR < 0.05),]
dim(genes_deg)#genes found to be differentially expressed
genes_deg$row <- row.names(genes_deg)
write_xlsx(genes_deg,"genes_deg_enitw_d3.xlsx")

# highly expressed genes
high <- genes_deg[genes_deg$logFC > 0,]
dim(high)


#low expressed genes
low <- genes_deg[genes_deg$logFC < 0,]
dim(low)

```


#### 3) Classification based on genes selected by regularized logistic regression

##### EN + Classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_en)
xdata_en <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_en)
colnames(xdata_en) <- paste0("Var", 1:50)
xdata_en$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_enplus <- matrix(0,5,times_boot)
kappa_enplus<- matrix(0,5,times_boot)
sensitivity_enplus<- matrix(0,5,times_boot)
specificity_enplus <- matrix(0,5,times_boot)
miscl_enplus <- matrix(0,5,times_boot)
fpos_enplus <- matrix(0,5,times_boot)
fneg_enplus <- matrix(0,5,times_boot)
auc_enplus <- matrix(0,5,times_boot)

acc_enplus_train <- matrix(0,5,times_boot)
kappa_enplus_train<- matrix(0,5,times_boot)
sensitivity_enplus_train<- matrix(0,5,times_boot)
specificity_enplus_train <- matrix(0,5,times_boot)
miscl_enplus_train <- matrix(0,5,times_boot)
fpos_enplus_train <- matrix(0,5,times_boot)
fneg_enplus_train <- matrix(0,5,times_boot)
auc_enplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_enplus <- vector("list")
ids_fn_svmL1_enplus <- vector("list")
ids_fn_svmR1_enplus <- vector("list")
ids_fn_logist1_enplus <- vector("list")
ids_fn_rf1_enplus <- vector("list")

ids_fp_tree1_enplus <- vector("list")
ids_fp_svmL1_enplus <- vector("list")
ids_fp_svmR1_enplus <- vector("list")
ids_fp_logist1_enplus <- vector("list")
ids_fp_rf1_enplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_en[ixs$train,]
  testing <- xdata_en[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[1,i] <- length(listafp)
  fneg_enplus[1,i] <- length(listafn)
  ids_fn_tree1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <-  predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[2,i] <- length(listafp)
  fneg_enplus[2,i] <- length(listafn)
  ids_fn_svmL1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[3,i] <- length(listafp)
  fneg_enplus[3,i] <- length(listafn)
  ids_fn_svmR1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[4,i] <- length(listafp)
  fneg_enplus[4,i] <- length(listafn)
  ids_fn_logist1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_enplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_enplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_enplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_enplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_enplus[5,i] <- length(listafp)
  fneg_enplus[5,i] <- length(listafn)
  ids_fn_rf1_enplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_enplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_enplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_enplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_enplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_enplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_enplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}

```


###### Measures of model performance train


- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity
```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg
```{r}
# fneg
fneg_trees <- fneg_enplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```



###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_enplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_enplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_enplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_enplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_enplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_enplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_enplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_enplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_enplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_enplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_enplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_enplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_enplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_enplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_enplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_enplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_enplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_enplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_enplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_enplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_enplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_enplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_enplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_enplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_enplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_enplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_enplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_enplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_enplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_enplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

##### iTwiner + classifiers

```{r}
xdata <- xdataT


ydata.raw <- as.data.frame(clinic1$class)
ydata.raw$row <- DATASET1$ID

#ydata.raw$class <- c(rep(0,28),rep(1,34))
 
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "P"] <- 0
ydata.raw$`clinic1$class`[ydata.raw$`clinic1$class` == "Pm"] <- 1
rownames(ydata.raw) <- DATASET1$ID

xdata <- xdata[rownames(xdata) %in% 
                         rownames(ydata.raw),]

ydata.raw <- as.data.frame(ydata.raw[rownames(ydata.raw) %in% 
                         rownames(xdata),])

xdata <- xdata[ order(row.names(xdata)), ]

ydata.raw <- ydata.raw[ order(row.names(ydata.raw)), ]



ydata <- as.data.frame(ydata.raw[,1:2])
colnames(ydata) <- c("class","id")

names <- as.vector(top50_itw)
xdata_iTwiner <- as.data.frame(xdata[,names])

nomesgenes <- colnames(xdata_iTwiner)
colnames(xdata_iTwiner) <- paste0("Var", 1:50)
xdata_iTwiner$type <- as.factor(ydata$class)
ydata$class <- as.numeric(ydata$class)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
times_boot <- 100

acc_tcoxplus <- matrix(0,5,times_boot)
kappa_tcoxplus<- matrix(0,5,times_boot)
sensitivity_tcoxplus<- matrix(0,5,times_boot)
specificity_tcoxplus <- matrix(0,5,times_boot)
miscl_tcoxplus <- matrix(0,5,times_boot)
fpos_tcoxplus <- matrix(0,5,times_boot)
fneg_tcoxplus <- matrix(0,5,times_boot)
auc_tcoxplus <- matrix(0,5,times_boot)

acc_tcoxplus_train <- matrix(0,5,times_boot)
kappa_tcoxplus_train<- matrix(0,5,times_boot)
sensitivity_tcoxplus_train<- matrix(0,5,times_boot)
specificity_tcoxplus_train <- matrix(0,5,times_boot)
miscl_tcoxplus_train <- matrix(0,5,times_boot)
fpos_tcoxplus_train <- matrix(0,5,times_boot)
fneg_tcoxplus_train <- matrix(0,5,times_boot)
auc_tcoxplus_train <- matrix(0,5,times_boot)

ids_fn_tree1_tcoxplus <- vector("list")
ids_fn_svmL1_tcoxplus <- vector("list")
ids_fn_svmR1_tcoxplus <- vector("list")
ids_fn_logist1_tcoxplus <- vector("list")
ids_fn_rf1_tcoxplus <- vector("list")

ids_fp_tree1_tcoxplus <- vector("list")
ids_fp_svmL1_tcoxplus <- vector("list")
ids_fp_svmR1_tcoxplus <- vector("list")
ids_fp_logist1_tcoxplus <- vector("list")
ids_fp_rf1_tcoxplus <- vector("list")



run = 1000


for (i in 1:times_boot){
  
  print(i)
  run = run + 11
  set.seed(run)
  print(run)
  
  ixs <- loose.rock::balanced.train.and.test(which(as.logical(ydata$class)), which(as.logical(!ydata$class)), train.perc = 0.7)
  
  training <- xdata_iTwiner[ixs$train,]
  testing <- xdata_iTwiner[ixs$test,]  
  
  
  
  
  # Classification - fazer todos com cross validation
  
  ## Decision tree
  # Fit the model on the training set
  
  control <- rpart.control(minsplit = 4)
  
  model2 <- rpart(type~., data = training, method = 'class', control = control)
  
  # TRain 
  pred <- model2 %>% predict(training, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[1,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[1,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[1,i] <- t[2,1]
  ###
  
  
  # Make predictions on the test data
  pred <- model2 %>% predict(testing, type = "class")
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[1,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[1,i] <- length(listafp)
  fneg_tcoxplus[1,i] <- length(listafn)
  ids_fn_tree1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_tree1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[1,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[1,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[1,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[1,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[1,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## SVM linear
  
  svm_Linear <- train(type ~., data = training, method = "svmLinear",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_Linear, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[2,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[2,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[2,i] <- t[2,1]
  ###
  
  # TEst
  
  pred <- predict(svm_Linear, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[2,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[2,i] <- length(listafp)
  fneg_tcoxplus[2,i] <- length(listafn)
  ids_fn_svmL1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmL1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[2,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[2,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[2,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[2,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[2,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  
  ## SVM radial
  
  svm_radial <- train(type ~., data = training, method = "svmRadial",
                      trControl=trainControl("cv", number = 10),
                      tuneLength = 10)
  
  # TRain 
  pred <- predict(svm_radial, newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[3,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[3,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[3,i] <- t[2,1]
  ###
  
  
  # Test
  pred <- predict(svm_radial, newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[3,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[3,i] <- length(listafp)
  fneg_tcoxplus[3,i] <- length(listafn)
  ids_fn_svmR1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_svmR1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[3,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[3,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[3,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[3,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[3,i] <- t[1,2]+t[2,1]
  ###
  
  
  
  ## Logistic Regression
  
  
  logist <- train(type ~., data = training, method = "LogitBoost",
                  trControl=trainControl("cv", number = 10),
                  tuneLength = 10)
  
  # TRain 
  pred <- predict(logist,newdata = training )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[4,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[4,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[4,i] <- t[2,1]
  ###
  
  
  #TEst
  pred <- predict(logist,newdata = testing )
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[4,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[4,i] <- length(listafp)
  fneg_tcoxplus[4,i] <- length(listafn)
  ids_fn_logist1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_logist1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus[4,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[4,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[4,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[4,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[4,i] <- t[1,2]+t[2,1]
  
  ###
  
  
  
  ## Random forest
  
  model.rf <- train(type ~., data = training, method = "rf",
                    trControl=trainControl("cv", number = 10),
                    tuneLength = 10)
  
  
  # TRain 
  pred <- predict(model.rf,newdata = training)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus_train[5,i] <- auc(training$type, a)
  
  #Calculating accuracy
  t <- table(pred,training$type)
  result <- confusionMatrix(t)
  
  acc_tcoxplus_train[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus_train[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus_train[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus_train[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus_train[5,i] <- t[1,2]+t[2,1]
  fneg_tcoxplus_train[5,i] <- t[2,1]
  ###
  
  
  #Test
  pred <- predict(model.rf,newdata = testing)
  a <- as.vector(pred)
  a <- as.numeric(a)
  
  auc_tcoxplus[5,i] <- auc(testing$type, a)
  
  true <- testing$type
  
  listafp <- c()
  listafn <- c()
  
  for (a in which(pred!= true)){
    
    if (pred[a] == 0) {
      
      listafp <- c(listafp, a)
    } else {
      listafn <- c(listafn, a)
    }
  }
  
  fpos_tcoxplus[5,i] <- length(listafp)
  fneg_tcoxplus[5,i] <- length(listafn)
  ids_fn_rf1_tcoxplus[[i]] <- rownames(testing[listafn,])
  ids_fp_rf1_tcoxplus[[i]] <- rownames(testing[listafp,])
  
  #Calculating accuracy
  
  t <- table(pred,testing$type)
  result <- confusionMatrix(t)
  
  
  acc_tcoxplus[5,i] <- result[["overall"]][["Accuracy"]]
  kappa_tcoxplus[5,i] <- result[["overall"]][["Kappa"]]
  sensitivity_tcoxplus[5,i] <- result[["byClass"]][["Sensitivity"]]
  specificity_tcoxplus[5,i] <- result[["byClass"]][["Specificity"]]
  miscl_tcoxplus[5,i] <- t[1,2]+t[2,1]
  
  
  
  
  ###
  
  
  
  
  rm(training,testing,a)
}
```


###### Measures of model performance train

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus_train[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus_train[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus_train[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus_train[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus_train[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc
```{r}
# auc
auc_trees <- auc_tcoxplus_train[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus_train[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus_train[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus_train[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus_train[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification

```{r}
# miscl
miscl_trees <- miscl_tcoxplus_train[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus_train[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus_train[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus_train[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus_train[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus_train[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus_train[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus_train[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus_train[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus_train[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity

```{r}
# specificity
specificity_trees <- specificity_tcoxplus_train[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus_train[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus_train[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus_train[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus_train[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus_train[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus_train[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus_train[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus_train[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus_train[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```


###### Measures of model performance test

- Accuracy 

```{r}
# acc
acc_trees <- acc_tcoxplus[1,]
#hist(acc_trees)
mean(acc_trees)
median(acc_trees)
sd(acc_trees)

acc_svm <- acc_tcoxplus[2,]
#hist(acc_svm)
mean(acc_svm)
median(acc_svm)
sd(acc_svm)

acc_svmR <- acc_tcoxplus[3,]
#hist(acc_svmR)
mean(acc_svmR)
median(acc_svmR)
sd(acc_svmR)

acc_logs <- acc_tcoxplus[4,]
#hist(acc_logs)
mean(acc_logs)
median(acc_logs)
sd(acc_logs)

acc_rf <- acc_tcoxplus[5,]
#hist(acc_rf)
mean(acc_rf)
median(acc_rf)
sd(acc_rf)

```

- auc

```{r}
# auc
auc_trees <- auc_tcoxplus[1,]
#hist(auc_trees)
mean(auc_trees)
median(auc_trees)
sd(auc_trees)

auc_svm <- auc_tcoxplus[2,]
#hist(auc_svm)
mean(auc_svm)
median(auc_svm)
sd(auc_svm)

auc_svmR <- auc_tcoxplus[3,]
#hist(auc_svmR)
mean(auc_svmR)
median(auc_svmR)
sd(auc_svmR)

auc_logs <- auc_tcoxplus[4,]
#hist(auc_logs)
mean(auc_logs)
median(auc_logs)
sd(auc_logs)

auc_rf <- auc_tcoxplus[5,]
#hist(auc_rf)
mean(auc_rf)
median(auc_rf)
sd(auc_rf)

```

- Misclassification
```{r}
# miscl
miscl_trees <- miscl_tcoxplus[1,]
#hist(miscl_trees)
mean(miscl_trees)
median(miscl_trees)
sd(miscl_trees)

miscl_svm <- miscl_tcoxplus[2,]
#hist(miscl_svm)
mean(miscl_svm)
median(miscl_svm)
sd(miscl_svm)

miscl_svmR <- miscl_tcoxplus[3,]
#hist(miscl_svmR)
mean(miscl_svmR)
median(miscl_svmR)
sd(miscl_svmR)

miscl_logs <- miscl_tcoxplus[4,]
#hist(miscl_logs)
mean(miscl_logs)
median(miscl_logs)
sd(miscl_logs)

miscl_rf <- miscl_tcoxplus[5,]
#hist(miscl_rf)
mean(miscl_rf)
median(miscl_rf)
sd(miscl_rf)

```

- Sensitivity

```{r}
# sensitivity
sensitivity_trees <- sensitivity_tcoxplus[1,]
#hist(sensitivity_trees)
mean(sensitivity_trees)
median(sensitivity_trees)
sd(sensitivity_trees)

sensitivity_svm <- sensitivity_tcoxplus[2,]
#hist(sensitivity_svm)
mean(sensitivity_svm)
median(sensitivity_svm)
sd(sensitivity_svm)

sensitivity_svmR <- sensitivity_tcoxplus[3,]
#hist(sensitivity_svmR)
mean(sensitivity_svmR)
median(sensitivity_svmR)
sd(sensitivity_svmR)

sensitivity_logs <- sensitivity_tcoxplus[4,]
#hist(sensitivity_logs)
mean(sensitivity_logs)
median(sensitivity_logs)
sd(sensitivity_logs)

sensitivity_rf <- sensitivity_tcoxplus[5,]
#hist(sensitivity_rf)
mean(sensitivity_rf)
median(sensitivity_rf)
sd(sensitivity_rf)

```

- Specificity
```{r}
# specificity
specificity_trees <- specificity_tcoxplus[1,]
#hist(specificity_trees)
mean(specificity_trees)
median(specificity_trees)
sd(specificity_trees)

specificity_svm <- specificity_tcoxplus[2,]
#hist(specificity_svm)
mean(specificity_svm)
median(specificity_svm)
sd(specificity_svm)

specificity_svmR <- specificity_tcoxplus[3,]
#hist(specificity_svmR)
mean(specificity_svmR)
median(specificity_svmR)
sd(specificity_svmR)

specificity_logs <- specificity_tcoxplus[4,]
#hist(specificity_logs)
mean(specificity_logs)
median(specificity_logs)
sd(specificity_logs)

specificity_rf <- specificity_tcoxplus[5,]
#hist(specificity_rf)
mean(specificity_rf)
median(specificity_rf)
sd(specificity_rf)

```

- False Neg

```{r}
# fneg
fneg_trees <- fneg_tcoxplus[1,]
#hist(fneg_trees)
mean(fneg_trees)
median(fneg_trees)
sd(fneg_trees)

fneg_svm <- fneg_tcoxplus[2,]
#hist(fneg_svm)
mean(fneg_svm)
median(fneg_svm)
sd(fneg_svm)

fneg_svmR <- fneg_tcoxplus[3,]
#hist(fneg_svmR)
mean(fneg_svmR)
median(fneg_svmR)
sd(fneg_svmR)

fneg_logs <- fneg_tcoxplus[4,]
#hist(fneg_logs)
mean(fneg_logs)
median(fneg_logs)
sd(fneg_logs)

fneg_rf <- fneg_tcoxplus[5,]
#hist(fneg_rf)
mean(fneg_rf)
median(fneg_rf)
sd(fneg_rf)

```

```{r}
# save results

#save.image("~/results3_2010_final.RData")
```



### Data final 

```{r}
dt3 <- acc[1,]
dt_en3 <- acc_enplus[1,]
dt_iTwiner3 <- acc_tcoxplus[1,]
#dt_hub <- acc_hubplus[1,]

acc_dt3 <- as.data.frame(c(dt3,dt_en3, dt_iTwiner3
                           #,dt_hub
))
colnames(acc_dt3) <- "acc"
#acc_dt$group <- "HUB + DT"
#acc_dt$group[1:100] <- "DT"
acc_dt3$group <- "DT"
acc_dt3$group[101:200] <- "EN + DT"
acc_dt3$group[201:300] <- "iTwiner + DT"
acc_dt3<- acc_dt3 %>% mutate_if(is.character,factor)
# acc_dt$group <- ordered(acc_dt$group, levels = c("DT", "EN + DT","iTwiner + DT", "HUB + DT"))
acc_dt3$group <- ordered(acc_dt3$group, levels = c("DT", "EN + DT","iTwiner + DT"))

acc_dt3$dataset <- "DATASET3"



svmL3 <- acc[2,]
svmL_en3 <- acc_enplus[2,]
svmL_iTwiner3 <- acc_tcoxplus[2,]

acc_svmL3 <- as.data.frame(c(svmL3,svmL_en3, svmL_iTwiner3
                             #,svmL_hub
))
colnames(acc_svmL3) <- "acc"
acc_svmL3$group <- "svmL"
acc_svmL3$group[101:200] <- "EN + svmL"
acc_svmL3$group[201:300] <- "iTwiner + svmL"
acc_svmL3<- acc_svmL3 %>% mutate_if(is.character,factor)
acc_svmL3$group <- ordered(acc_svmL3$group, levels = c("svmL", "EN + svmL","iTwiner + svmL"))

acc_svmL3$dataset <- "DATASET3"




svmR3 <- acc[3,]
svmR_en3 <- acc_enplus[3,]
svmR_iTwiner3 <- acc_tcoxplus[3,]

acc_svmR3 <- as.data.frame(c(svmR3,svmR_en3, svmR_iTwiner3
                             #,svmR_hub
))
colnames(acc_svmR3) <- "acc"
acc_svmR3$group <- "svmR"
acc_svmR3$group[101:200] <- "EN + svmR"
acc_svmR3$group[201:300] <- "iTwiner + svmR"
acc_svmR3<- acc_svmR3 %>% mutate_if(is.character,factor)
acc_svmR3$group <- ordered(acc_svmR3$group, levels = c("svmR", "EN + svmR","iTwiner + svmR"))

acc_svmR3$dataset <- "DATASET3"






logist3 <- acc[4,]
logist_en3 <- acc_enplus[4,]
logist_iTwiner3 <- acc_tcoxplus[4,]

acc_logist3 <- as.data.frame(c(logist3,logist_en3, logist_iTwiner3
                               #,logist_hub
))
colnames(acc_logist3) <- "acc"
acc_logist3$group <- "logist"
acc_logist3$group[101:200] <- "EN + logist"
acc_logist3$group[201:300] <- "iTwiner + logist"
acc_logist3<- acc_logist3 %>% mutate_if(is.character,factor)
acc_logist3$group <- ordered(acc_logist3$group, levels = c("logist", "EN + logist","iTwiner + logist"))

acc_logist3$dataset <- "DATASET3"






rf3 <- acc[5,]
rf_en3 <- acc_enplus[5,]
rf_iTwiner3 <- acc_tcoxplus[5,]

acc_rf3 <- as.data.frame(c(rf3,rf_en3, rf_iTwiner3
                           #,rf_hub
))
colnames(acc_rf3) <- "acc"
acc_rf3$group <- "rf"
acc_rf3$group[101:200] <- "EN + rf"
acc_rf3$group[201:300] <- "iTwiner + rf"
acc_rf3<- acc_rf3 %>% mutate_if(is.character,factor)
acc_rf3$group <- ordered(acc_rf3$group, levels = c("rf", "EN + rf","iTwiner + rf"))

acc_rf3$dataset <- "DATASET3"





```









# final results

- Plots comparing data partitions after running chunk bellow (line 208) for the three distinct datasets

```{r}
# Libraries
library(ggplot2)
library(dplyr)
library(forcats)
library(hrbrthemes)
library(viridis)

# Load dataset from github
data_dt <- rbind(acc_dt1,acc_dt2,acc_dt3)


p <- ggplot(data_dt, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="DT",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmL <- rbind(acc_svmL1,acc_svmL2,acc_svmL3)


p <- ggplot(data_svmL, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmL",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmR <- rbind(acc_svmR1,acc_svmR2,acc_svmR3)


p <- ggplot(data_svmR, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmR",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )






data_logis <- rbind(acc_logist1,acc_logist2,acc_logist3)


p <- ggplot(data_logis, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="LR",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )







data_rf <- rbind(acc_rf1,acc_rf2,acc_rf3)


p <- ggplot(data_rf, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="RF",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )


```


# final plots comparing data partitions

```{r}
# Libraries
library(ggplot2)
library(dplyr)
library(forcats)
library(hrbrthemes)
library(viridis)

# Load dataset from github
data_dt <- rbind(acc_dt1,acc_dt2,acc_dt3)


p <- ggplot(data_dt, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmL <- rbind(acc_svmL1,acc_svmL2,acc_svmL3)


p <- ggplot(data_svmL, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmL",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )





data_svmR <- rbind(acc_svmR1,acc_svmR2,acc_svmR3)


p <- ggplot(data_svmR, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="svmR",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )






data_logis <- rbind(acc_logist1,acc_logist2,acc_logist3)


p <- ggplot(data_logis, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Logistic",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )







data_rf <- rbind(acc_rf1,acc_rf2,acc_rf3)


p <- ggplot(data_rf, aes(x = group , y = acc, fill = dataset )) + geom_boxplot()

p <- p + theme_bw() 
p + scale_fill_brewer(palette="Pastel1") + labs(title="Random Forest",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold") )


```

# Final Stasts

## DT 
all decision trees
```{r}
stat.test <- compare_means(acc ~ dataset, data = data_dt, 
              group.by = "group", paired = F, p.adjust.method = "BH")
stat.test

ggboxplot(data_dt, x = "group", y = "acc",
          fill = "dataset") + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold"), legend.title = element_blank())

#p + stat_compare_means(aes(group = dataset))

#stat_compare_means(label.y = 50)     

#aes(group = dataset),comparisons = my_comparisons
```


DT 

```{r}
dt_stats <- as.data.frame(data_dt[c(1:100,301:400,601:700),])

# Statistical test
stat.test <- compare_means(acc ~ dataset, data = dt_stats, 
              group.by = "group", paired = F, p.adjust.method = "BH")
stat.test

# Box plot
my_comparisons <- list( c("DATASET1", "DATASET2"), c("DATASET1", "DATASET3"), c("DATASET2", "DATASET3"))

ggboxplot(dt_stats, x = "dataset", y = "acc", fill = "dataset")  + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="DT", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold"),legend.position = "none") + stat_compare_means(comparisons = my_comparisons,label = "p.signif")

```


DT + EN

```{r}
dt_en_stats <- as.data.frame(data_dt[c(101:200,401:500,701:800),])

# Statistical test
stat.test <- compare_means(acc ~ dataset, data = dt_en_stats, 
              group.by = "group", paired = F, p.adjust.method = "BH")
stat.test

# Box plot
my_comparisons <- list( c("DATASET1", "DATASET2"), c("DATASET1", "DATASET3"), c("DATASET2", "DATASET3"))

ggboxplot(dt_en_stats, x = "dataset", y = "acc", fill = "dataset")  + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="DT + EN", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold"),legend.position = "none") + stat_compare_means(comparisons = my_comparisons,label = "p.signif")

```


DT + iTW

```{r}
dt_itw_stats <- as.data.frame(data_dt[c(201:300,501:600,801:900),])

# Statistical test
stat.test <- compare_means(acc ~ dataset, data = dt_itw_stats, 
              group.by = "group", paired = F, p.adjust.method = "BH")
stat.test

# Box plot
my_comparisons <- list( c("DATASET1", "DATASET2"), c("DATASET1", "DATASET3"), c("DATASET2", "DATASET3"))

ggboxplot(dt_itw_stats, x = "dataset", y = "acc", fill = "dataset")  + scale_fill_brewer(palette="Pastel1") + labs(title="Decision Trees",x="DT + iTW", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold"),legend.position = "none") + stat_compare_means(comparisons = my_comparisons,label = "p.signif")
```

## svmL

all svmL
```{r}
stat.test <- compare_means(acc ~ dataset, data = data_svmL, 
              group.by = "group", paired = F, p.adjust.method = "BH")
stat.test

ggboxplot(data_svmL, x = "group", y = "acc",
          fill = "dataset") + scale_fill_brewer(palette="Pastel1") + labs(title="svmL",x="Method", y = "Acc") + theme(plot.title = element_text(size = 16, face = "bold.italic", hjust = 0.5),  axis.text = element_text(size = 12), axis.title=element_text(size=14,face="bold"), legend.title = element_blank())
```

## svmR
svmR 

```{r}
svmR_stats <- as.data.frame(data_svmR[c(1:100,301:400,601:700),c(1,3)])

colnames(svmR_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = svmR_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(svmR_stats$acc, svmR_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

svmR + EN

```{r}
svmR_en_stats <- as.data.frame(data_svmR[c(101:200,401:500,701:800),c(1,3)])

colnames(svmR_en_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = svmR_en_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(svmR_en_stats$acc, svmR_en_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

svmR + iTW

```{r}
svmR_itw_stats <- as.data.frame(data_svmR[c(201:300,501:600,801:900),c(1,3)])

colnames(svmR_itw_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = svmR_itw_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(svmR_itw_stats$acc, svmR_itw_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

## Logis
logis

```{r}
logis_stats <- as.data.frame(data_logis[c(1:100,301:400,601:700),c(1,3)])

colnames(logis_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = logis_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(logis_stats$acc, logis_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

logis + EN

```{r}
logis_en_stats <- as.data.frame(data_logis[c(101:200,401:500,701:800),c(1,3)])

colnames(logis_en_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = logis_en_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(logis_en_stats$acc, logis_en_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

logis + iTW

```{r}
logis_itw_stats <- as.data.frame(data_logis[c(201:300,501:600,801:900),c(1,3)])

colnames(logis_itw_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = logis_itw_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(logis_itw_stats$acc, logis_itw_stats$group,
                            p.adjust.method = "BH")

res$p.value
```


## RF
rf 

```{r}
rf_stats <- as.data.frame(data_rf[c(1:100,301:400,601:700),c(1,3)])

colnames(rf_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = rf_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(rf_stats$acc, rf_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

rf + EN

```{r}
rf_en_stats <- as.data.frame(data_rf[c(101:200,401:500,701:800),c(1,3)])

colnames(rf_en_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = rf_en_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(rf_en_stats$acc, rf_en_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

rf + iTW

```{r}
rf_itw_stats <- as.data.frame(data_rf[c(201:300,501:600,801:900),c(1,3)])

colnames(rf_itw_stats) <- c("acc", "group")

#Kruskal-Wallis test

kruskal.test(acc ~ group, data = rf_itw_stats)

#pairwise.wilcox.test() to calculate pairwise comparisons between group levels with corrections for multiple testing

res <- pairwise.wilcox.test(rf_itw_stats$acc, rf_itw_stats$group,
                            p.adjust.method = "BH")

res$p.value
```

```{r}
save.image("~/paper_final.RData")
```


